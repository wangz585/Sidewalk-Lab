{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Visitor Behaviour at 307 Using De-identified Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Content\n",
    "\n",
    "### 0. Context and Preview\n",
    "\n",
    "### 1. Pedestrian Count and Dwell Time\n",
    "\n",
    "- 1.1 Long-Term Trend\n",
    "- 1.2 Peak Days Summary\n",
    "- 1.3 Overall Distribution\n",
    "- 1.4 Grouping by Time\n",
    "- 1.5 Averaged Proportion\n",
    "- 1.6 On Events\n",
    "\n",
    "### 2. Desired Lines and Spots\n",
    "- 2.1 On Events Summary\n",
    "\n",
    "### 3. Maintenance Schedule\n",
    "- 3.1 Maintenance Schedule by Pedestrian Count or Dwell Time\n",
    "- 3.2 Maintenance Time During the Day\n",
    "\n",
    "### Privacy Philosopy\n",
    "1. Data collection\n",
    "2. Data processing\n",
    "3. Future improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg \n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib import colors as mcolors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly as py\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot, init_notebook_mode\n",
    "#init_notebook_mode(connected=True)\n",
    "\n",
    "import cufflinks as cf\n",
    "cf.go_offline(connected=True)\n",
    "cf.set_config_file(colorscale='plotly', world_readable=True)\n",
    "\n",
    "# Extra options\n",
    "# pd.options.display.max_rows = 30\n",
    "# pd.options.display.max_columns = 25\n",
    "\n",
    "# Show all code cells outputs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "import os\n",
    "from IPython.display import Image, display, HTML\n",
    "\n",
    "import time\n",
    "from time import time, sleep\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store login data in login.py\n",
    "%run login.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# login query as multiline formatted string\n",
    "# this assumes that login and pwd are defined \n",
    "# above\n",
    "\n",
    "loginquery = f\"\"\"\n",
    "mutation {{\n",
    "  logIn(\n",
    "      email:\\\"{login}\\\",\n",
    "      password:\\\"{pwd}\\\") {{\n",
    "    jwt {{\n",
    "      token\n",
    "      exp\n",
    "    }}\n",
    "  }}\n",
    "}}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "url = 'https://api.numina.co/graphql'\n",
    "\n",
    "mylogin = requests.post(url, json={'query': loginquery})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = mylogin.json()['data']['logIn']['jwt']['token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "expdate = mylogin.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Context and Preview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 Purpose of the Webpage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This webpage aims to provide a tool for the users to understand and explore data collected at the [307 area](https://www.azuremagazine.com/article/sidewalk-labs-307/) of the [Sidewalk Labs](https://www.sidewalklabs.com/). The webpage focuses on exploratory analysis and mainly consists of interactive widgets. While we offer a few of our own insights, the users are strongly encouraged to try different settings of the widgets to make more observations. \n",
    "\n",
    "This webpage also aims to explore whether a balance could be reached between data analysis and privacy preservation. All data used and collected here has been deidentified. Please consult the documentation for more information on the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 Devices and Zones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 307 area consists of three areas, each covered by one device (i.e. Numina sensor). The following images present the three areas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Streetscape | Under Raincoat | Outside\n",
    "------------- | -------------  | -------------\n",
    "![alt](streetscape_sandbox.png) | ![alt](underraincoat_sandbox.png) | ![alt](outside_sandbox.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in the above images, each area essentially consists of two parts: objects such as tables and chairs, and empty spaces presumably for walking. Based on this reasoning, we have defined the following smaller behaviour zones so as to perform more in-depth research:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Streetscape:**\n",
    "\n",
    "Chair Zone | Corridor Zone | Free Zone\n",
    "------------- | -------------  | -------------\n",
    "![alt](BehaviorZoneImage/Streetscape-ChairZone.png) | ![alt](BehaviorZoneImage/Streetscape-PathZone.png) | ![alt](BehaviorZoneImage/Streetscape-ActivityZone.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Under Raincoat**\n",
    "\n",
    "Chair Zone | Traffic Zone | Free Zone\n",
    "------------- | -------------  | -------------\n",
    "![alt](BehaviorZoneImage/UnderRaincoat-ChairZone.png) | ![alt](BehaviorZoneImage/UnderRaincoat-TrafficZone.png) | ![alt](BehaviorZoneImage/UnderRaincoat-ActivityZone.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outside**\n",
    "\n",
    "Chair Zone | Path Zone | -\n",
    "------------- | -------------  | -------------\n",
    "![alt](BehaviorZoneImage/Outside-ChairZone.png) | ![alt](BehaviorZoneImage/Outside-PathZone.png) | ![alt](blank.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we have to be aware of the fact that the chairs can be moved and that the above images may not necessarily reflect the layout of the room during the whole period of data collection. Specifically, the three sets of chairs in the Under Raincoat area can be easily moved. Thus, for the purpose of this webpage, we will not be investigating the Chair Zone of Under Raincoat; instead, we will integrate any analysis of the chairs into the analysis of the Free Zone, since it is presumably safe to assume that the chairs would not be moved outside the Free Zone to the Traffic Zone.\n",
    "\n",
    "Similarly, in the Streetscape area, under the assumption that it is intended to place the chairs together, it is unlikely that the group of chairs would be moved around freely and frequently due to the other obstacles in the room. As for the Outside area, it is also unlikely that the chairs would be placed in the middle of the road to block the path. Thus, we will be analyzing these two Chair Zones (while keeping the limitation in mind)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pedestrian Count and Dwell Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section explores where pedestrians tended to pass through and to linger by visualizing the count and dwell time data.\n",
    "\n",
    "Tips on using the widgets:\n",
    "- click on the legend to include / exclude a trace; we strongly suggest to select only a subset when grouping the data by zones\n",
    "- move the x-axis range slider to adjust the scale\n",
    "- each area/zone has been assigned a unique colour: blues are Streetscape zones, reds are Under Raincoat zones and greens are Outside zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device info\n",
    "device_dict = {'SWLSANDBOX1':'Streetscape', 'SWLSANDBOX2':'Under Raincoat', 'SWLSANDBOX3':'Outside'}\n",
    "device_ids = list(device_dict.keys())\n",
    "device_names = list(device_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zones(device_id):\n",
    "    '''\n",
    "    a query to get all zones within the areas included in the device_id list;\n",
    "    returns a df\n",
    "    '''\n",
    "    query_zones = \"\"\"\n",
    "    query {{\n",
    "      behaviorZones (\n",
    "        serialnos: \"{0}\"\n",
    "        ) {{\n",
    "        count\n",
    "        edges {{\n",
    "          node {{\n",
    "            rawId\n",
    "            text\n",
    "          }}\n",
    "        }}\n",
    "      }}\n",
    "    }}\n",
    "    \"\"\".format(device_id)\n",
    "    \n",
    "    zones = requests.post(url, json={'query': query_zones}, headers = {'Authorization':token})\n",
    "    \n",
    "    df = pd.DataFrame([x['node'] for x in zones.json()['data']['behaviorZones']['edges']])\n",
    "    df['device_id'] = device_id\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a df for zones\n",
    "\n",
    "# get zones\n",
    "zones_df = pd.concat([get_zones(device_ids[i]) for i in range(3)])\n",
    "zones_df = zones_df[(zones_df.text.notnull()) & \n",
    "                    (zones_df.text.str.startswith('x-')) & \n",
    "                    (zones_df.text.str.endswith('zone'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# adjusts zone info\n",
    "\n",
    "# modify zone name and add a type\n",
    "zones_df['text'] = zones_df['text'].str.replace('x-', '')\n",
    "zones_df['type'] = ['path', 'rest', 'both', 'path', 'both', 'rest', 'path']\n",
    "\n",
    "# colour of zones - 3 blues, 2 reds, 2 greens\n",
    "zone_clrs = ['royalblue', 'deepskyblue', 'dodgerblue',\n",
    "             'lightcoral', 'orangered', \n",
    "             'mediumaquamarine', 'mediumseagreen']\n",
    "\n",
    "# zone ID from int to str\n",
    "zones_df.rawId = zones_df.rawId.astype(str)\n",
    "zone_name_dict = dict(zip(zones_df.rawId, zones_df.text))\n",
    "zone_type_dict = dict(zip(zones_df.rawId, zones_df.type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dwell(func, ID, interval):\n",
    "    '''\n",
    "    func is either feedDwellTimeDistribution or zoneDwellTimeDistribution;\n",
    "    a query to get dwell info in area/zone identified by ID;\n",
    "    returns a preprocessed dataframe\n",
    "    '''\n",
    "    if func == 'feedDwellTimeDistribution':\n",
    "        arg = 'serialnos: \"{0}\"'.format(ID)\n",
    "    else:\n",
    "        arg = 'zoneIds: {0}'.format(ID)\n",
    "        \n",
    "    query = \"\"\"\n",
    "    query {{\n",
    "        {0}(\n",
    "        {1},\n",
    "        startTime: \"2019-02-20T00:00:00\",\n",
    "        endTime: \"2020-01-12T00:00:00\",\n",
    "        timezone: \"America/New_York\",\n",
    "        objClasses: [\"pedestrian\"],\n",
    "        interval: \"{2}\"\n",
    "        ){{\n",
    "        edges {{\n",
    "          node {{\n",
    "            time\n",
    "            objClass\n",
    "            pct100\n",
    "            pct75\n",
    "            pct50\n",
    "            pct25\n",
    "            mean\n",
    "            count\n",
    "          }}\n",
    "        }}\n",
    "      }}\n",
    "    }}\n",
    "    \"\"\".format(func, arg, interval)\n",
    "\n",
    "    dwell = requests.post(url, json={'query': query}, \n",
    "                           headers = {'Authorization':token})\n",
    "    \n",
    "    # traverse to only keep useful info\n",
    "    df = pd.DataFrame([x['node'] for x in dwell.json()['data'][func]['edges']])\n",
    "    # add a column\n",
    "    if func == 'feedDwellTimeDistribution':\n",
    "        df['device_id'] = ID\n",
    "    else:\n",
    "        df['zone_id'] = ID\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    '''\n",
    "    preprocesses a dataframe returned by feedDwellTimeDistribution/zoneDwellTimeDistribution\n",
    "    '''\n",
    "    # replace NaN with 0\n",
    "    df = df.fillna(0)\n",
    "    # convert time\n",
    "    df['time'] = df['time'].str[:-6].apply(lambda x : pd.Timestamp(x))\n",
    "    df['month'] = df['time'].dt.month\n",
    "    df['dayofweek'] = df['time'].dt.dayofweek\n",
    "    df['hour'] = df['time'].dt.hour\n",
    "    df['date'] = df['time'].dt.date\n",
    "    \n",
    "    # add either zone or device name\n",
    "    if 'zone_id' in df.columns:\n",
    "        df.zone_id = df.zone_id.astype(str)\n",
    "        df['zone'] = [zone_name_dict[z] for z in df.zone_id]\n",
    "        df['zone_type'] = [zone_type_dict[z] for z in df.zone_id]\n",
    "    else:\n",
    "        df['device'] = [device_dict[d] for d in df.device_id]\n",
    "    \n",
    "    # add a total column = mean * count\n",
    "    df['total_dwell'] = df['mean'] * df['count']\n",
    "    df = df.rename(columns={'mean':'mean_dwell', 'pct50':'median_dwell', 'pct100':'max_dwell'})\n",
    "    df = df.drop(['pct75', 'pct25'], axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hourly dwell time \n",
    "# device\n",
    "feed_dwell_1h_df = pd.concat([get_dwell('feedDwellTimeDistribution', device_ids[i], '1h') \n",
    "                              for i in range(3)])\n",
    "# zone\n",
    "zone_dwell_1h_df = pd.concat([get_dwell('zoneDwellTimeDistribution', z, '1h')\n",
    "                             for z in zones_df['rawId'].values])\n",
    "feed_dwell_1h_df = preprocess(feed_dwell_1h_df)\n",
    "zone_dwell_1h_df = preprocess(zone_dwell_1h_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# daily dwell time \n",
    "# device\n",
    "feed_dwell_1d_df = pd.concat([get_dwell('feedDwellTimeDistribution', device_ids[i], '1d') \n",
    "                              for i in range(3)])\n",
    "# zone\n",
    "zone_dwell_1d_df = pd.concat([get_dwell('zoneDwellTimeDistribution', z, '1d')\n",
    "                             for z in zones_df['rawId'].values])\n",
    "feed_dwell_1d_df = preprocess(feed_dwell_1d_df)\n",
    "zone_dwell_1d_df = preprocess(zone_dwell_1d_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(groupby, interval):\n",
    "    '''\n",
    "    helper function to be called by other functions\n",
    "    '''\n",
    "    if groupby == 'device' and interval == '1d':\n",
    "        return feed_dwell_1d_df.copy(), device_names\n",
    "    elif groupby == 'zone' and interval == '1d':\n",
    "        return zone_dwell_1d_df.copy(), list(zones_df.text)\n",
    "    elif groupby == 'device' and interval == '1h':\n",
    "        return feed_dwell_1h_df.copy(), device_names\n",
    "    elif groupby == 'zone' and interval == '1h':\n",
    "        return zone_dwell_1h_df.copy(), list(zones_df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list = ['count', 'mean_dwell', 'max_dwell', 'median_dwell', 'total_dwell']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Long-Term Trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_timeline(groupby, metric):\n",
    "    '''\n",
    "    groupby is either 'device' or 'zone';\n",
    "    metric is a value in metric_list\n",
    "    '''\n",
    "    df, _ = get_df(groupby, '1d')\n",
    "    \n",
    "    # line plot\n",
    "    fig = px.line(df, x='time', y=metric, color=groupby, \n",
    "                  title='Trend in Daily Pedestrian ' +\\\n",
    "                        metric.replace('_', ' ').title() + ' Grouped by '+groupby.capitalize())\n",
    "    \n",
    "    # layout - axes labels\n",
    "    fig.update_layout(\n",
    "        xaxis_rangeslider_visible=True\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca7c7f629bb341eda83ff1ad75c6e45a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(RadioButtons(description='groupby', options=('device', 'zone'), value='device'), Dropdow…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = interact(plot_timeline, \n",
    "             groupby=widgets.RadioButtons(options=['device', 'zone'], value='device'),\n",
    "             metric=widgets.Dropdown(options=metric_list, value='mean_dwell')\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a general observation, there is no obvious increasing/decreasing trend (but rather frequent ups and downs) in any of the metric in the past year.\n",
    "\n",
    "We observe the count (and thus the total dwell time) in the Streetscape area has been siginificantly higher than the other two areas. Meanwhile, we see that peaks in mean dwell time tended to occur in Streetscape, and peaks in max dwell time tended to occur in either Streetscape or Outside. From either perspective, the Under Raincoat area is not as popular."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Peak Days Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are interested in researching about the reason about the peaks, the following interactive dataframe summarizes the exact locations and dates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d02cb5878cc4be295d3a713fc52bfd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(RadioButtons(description='groupby', options=('device', 'zone'), value='device'), Dropdow…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sort_dwell_1d(groupby, sortby, ascending, top):\n",
    "    '''\n",
    "    display a dataframe summarizing the area/zone and times of the top days\n",
    "    in either descending or ascending order\n",
    "    '''\n",
    "    df, _ = get_df(groupby, '1d')\n",
    "    \n",
    "    # weekday name\n",
    "    df['dayofweek'] = df['time'].dt.day_name()\n",
    "    \n",
    "    # column list\n",
    "    cols = [groupby, 'time', 'dayofweek', sortby]\n",
    "    if sortby == 'count':\n",
    "        cols.append('mean_dwell')\n",
    "    elif sortby == 'mean_dwell':\n",
    "        cols.append('count')\n",
    "    else:\n",
    "        cols.append('count')\n",
    "        cols.append('mean_dwell')\n",
    "        \n",
    "    display(df.sort_values(sortby, ascending=ascending).reset_index(drop=True)\n",
    "              .loc[:int(top)-1, cols])\n",
    "\n",
    "_ = interact(sort_dwell_1d, \n",
    "             groupby=widgets.RadioButtons(options=['device', 'zone'], value='device'),\n",
    "             sortby=widgets.Dropdown(options=metric_list, value='mean_dwell'),\n",
    "             top=widgets.IntSlider(value=5, min=1, max=30, step=1, readout_format='d'),\n",
    "             ascending=widgets.Checkbox(value=False, description='ascending'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Overall Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following widget would allow you to compare the statistics/distribution of a metric across the three areas (ex. the medians of mean dwell time). As mentioned, we highly recommend to focus on device groups only at this point; if you are interested in the zones, we recommend to select only a subset by clicking the legend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_boxplot(groupby, metric):\n",
    "    '''\n",
    "    plots box plot distribution of metric in metric list\n",
    "    '''\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # colours\n",
    "    if groupby == 'zone':\n",
    "        clrs = zone_clrs\n",
    "    else:\n",
    "        # default colours in sequence named plotly\n",
    "        # to be consistent\n",
    "        clrs = ['#636DFA', '#EF553B', '#00CC96']\n",
    "        \n",
    "    df, byvals = get_df(groupby, '1d')\n",
    "    \n",
    "    for i in range(len(byvals)):\n",
    "        # Use x instead of y argument for horizontal plot\n",
    "        fig.add_trace(go.Box(x=df.loc[df[groupby]==byvals[i], metric], name=byvals[i],\n",
    "                             boxpoints='outliers', boxmean=True, marker_color=clrs[i]))\n",
    "\n",
    "    # layout - axes labels\n",
    "    fig.update_layout(\n",
    "        xaxis_title=metric,\n",
    "        xaxis_rangeslider_visible=True,\n",
    "        title='Distribution of Pedestrian ' + \\\n",
    "              metric.replace('_', ' ').title() + ' Grouped by Device'\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "230157f2817d4b3d80668106e8a28fb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(RadioButtons(description='groupby', options=('device', 'zone'), value='device'), Dropdow…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = interact(plot_boxplot, groupby=widgets.RadioButtons(options=['device', 'zone'], value='device'),\n",
    "             metric=widgets.Dropdown(options=metric_list, value='count')\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The count distributions are extremely right-skewed. There is a significant difference between the count in Streetscape and the counts in the other two areas, suggesting that people tended to pass through the indoor area more often. In comparison, the distributions of the metrics related to dwell time are relatively more similar across the three areas. \n",
    "\n",
    "Given that we are working with time series data, let's take the factor of time into consideration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Grouping by Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_timegroup(groupby, metric, timegroup):\n",
    "    '''\n",
    "    plots metric of each groupby ('device' or 'zone') \n",
    "    by timegroup ('hour', 'date', 'dayofweek', 'month')\n",
    "    using a grouped barplot\n",
    "    '''\n",
    "    # get either 1d or 1h depending on time group\n",
    "    if timegroup == 'hour':\n",
    "        df, byvals = get_df(groupby, '1h')\n",
    "    else:\n",
    "        df, byvals = get_df(groupby, '1d')\n",
    "    \n",
    "    # colours\n",
    "    if groupby == 'device':\n",
    "        # default colours\n",
    "        clr = None\n",
    "    else:\n",
    "        clr = zone_clrs\n",
    "        \n",
    "    # convert dayofweek\n",
    "    weekdays = {0:'Monday', 1:'Tuesday', 2:'Wednesday', 3:'Thursday', 4:'Friday', 5:'Saturday', 6:'Sunday'}\n",
    "    df['dayofweek'] = [weekdays[w] for w in df['dayofweek']]\n",
    "    \n",
    "    # group\n",
    "    df = df.groupby([timegroup, groupby]).median().reset_index()\n",
    "    \n",
    "    # plot\n",
    "    fig = px.bar(df, x=timegroup, y=metric, color=groupby,\n",
    "                 category_orders={groupby:byvals, 'dayofweek':list(weekdays.values())}, # order of categories\n",
    "                 color_discrete_sequence=clr, # colour of devices/zones\n",
    "                 title='Median of Pedestrian ' + metric.replace('_', ' ').title() + ' Grouped by ' +\\\n",
    "                        timegroup.title() + ' and ' + groupby.title(),\n",
    "                 barmode='group')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31286b395d174f6e8ba35362f78ca4e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(RadioButtons(description='groupby', options=('device', 'zone'), value='device'), Dropdow…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = interact(plot_timegroup, \n",
    "             groupby=widgets.RadioButtons(options=['device', 'zone'], value='device'),\n",
    "             metric=widgets.Dropdown(options=metric_list, value='count'),\n",
    "             timegroup=widgets.Dropdown(options=['hour', 'dayofweek', 'month'], value='dayofweek'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the median value of daily pedestrian data statistics grouped by weekdays, we observe surprisingly that Saturday is a very special day, in which both the count and (mean/max) dwell time in the Streetscape (indoor) area are significantly less than the other days of the week.\n",
    "\n",
    "As for 'month', we see that in more than half of the days in Febraury, March, April and May, no pedestrians have been detected in the Outside area; similarly, there were no pedestrians in the Under Raincoat area in more than half of the days in November to March. \n",
    "\n",
    "The reasons behind these observations are not clear without further information such as maintenance schedule of the devices/cameras. We highly encourage you to investigate the reasons behind having no visits if the cameras were actually in service. \n",
    "\n",
    "On the other hand, it is more reasonable to see the median values of 'count' being all 0 from 11pm to 6am. We observe a normal distribution for the count in the Outside and Under Raincoat areas but a gap between 5pm and 8pm for the Streetscape area. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Averaged Proportion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we consider all data together, then the Streetscape area accounted for about 77.2% of all dwell time in the 307, followed by Outside (14.8%) and Under Raincoat (8%). Now in place of the exact values of the metrics, let's look at the proportions (in terms of pedestrian count and total dwell time) grouped by time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_prop_helper(df, col, newcol, lower_bound):\n",
    "    '''\n",
    "    helper function for compute_prop;\n",
    "    newcol is proportion wrt col\n",
    "    '''\n",
    "    # group by time (date + hour)\n",
    "    m = df.groupby('time').sum()\n",
    "    \n",
    "    # compute proportion wrt the total at each time\n",
    "    # add 0.00001 to avoid division by zero\n",
    "    df[newcol] = df.apply(lambda x : x[col] / (0.00001 + m.loc[x['time'], col]), axis=1)\n",
    "    \n",
    "    # only keep the times where the total count/dwell time is at least lower_bound\n",
    "    sub = df[df['time'].isin(list(m[m['count']>=lower_bound].index))]\n",
    "    \n",
    "    return sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_prop(df, lower_bound):\n",
    "    '''\n",
    "    computes proportion of count and total_dwell wrt the total at the time;\n",
    "    only keep days/hours in which the total value is at least lower_bound;\n",
    "    adds two new columns - count_prop and total_dwell_prop\n",
    "    '''\n",
    "    df = df.copy()\n",
    "    df = compute_prop_helper(df, 'count', 'count_prop', lower_bound)\n",
    "    df = compute_prop_helper(df, 'total_dwell', 'total_dwell_prop', lower_bound)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prop(groupby, metric, timegroup, lower_bound):\n",
    "    '''\n",
    "    plots proportion of metric ('count' or 'total_dwell')\n",
    "    of each groupby ('device' or 'zone') \n",
    "    by timegroup ('hour', 'date', 'dayofweek', 'month');\n",
    "    lower_bound is on the total value at a time\n",
    "    '''\n",
    "    # get either 1d or 1h depending on time group\n",
    "    if timegroup == 'hour':\n",
    "        df, byvals = get_df(groupby, '1h')\n",
    "    else:\n",
    "        df, byvals = get_df(groupby, '1d')\n",
    "    \n",
    "    # colours\n",
    "    if groupby == 'device':\n",
    "        # default colours\n",
    "        clr = None\n",
    "    else:\n",
    "        clr = zone_clrs\n",
    "        \n",
    "    # order of dayofweek\n",
    "    weekdays = {0:'Monday', 1:'Tuesday', 2:'Wednesday', 3:'Thursday', 4:'Friday', 5:'Saturday', 6:'Sunday'}\n",
    "    df['dayofweek'] = [weekdays[w] for w in df['dayofweek']]\n",
    "    \n",
    "    # add proportion columns\n",
    "    df = compute_prop(df, lower_bound)\n",
    "    # group\n",
    "    df = df.groupby([timegroup, groupby]).mean().reset_index()\n",
    "    \n",
    "    # plot\n",
    "    fig = px.bar(df, x=timegroup, y=metric+'_prop', color=groupby,\n",
    "                 category_orders={groupby:byvals, 'dayofweek':list(weekdays.values())}, # order of categories\n",
    "                 color_discrete_sequence=clr, # colour of devices/zones\n",
    "                 title='Averaged Proportion of ' + metric.replace('_', ' ').title() +\\\n",
    "                       ' Accounted for by Each ' + groupby.title(),\n",
    "                 range_y=(0, 1), labels={metric+'_prop':metric.replace('_', ' ')+' proportion'})\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df69f7337d6d473596a88235c9ecd1a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(RadioButtons(description='groupby', index=1, options=('device', 'zone'), value='zone'), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = interact(plot_prop, \n",
    "             groupby=widgets.RadioButtons(options=['device', 'zone'], value='zone'),\n",
    "             metric=widgets.RadioButtons(options=['count', 'total_dwell'], value='total_dwell'),\n",
    "             timegroup=widgets.Dropdown(options=['hour', 'date', 'dayofweek', 'month'], value='hour'),\n",
    "             lower_bound=widgets.IntSlider(value=50, min=0, max=2000, step=50, continuous_update=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While both the Outside and the Streescape areas have a chair zone of a similar size, the chair zone in the Streetscape area tended to account for much more of the data in the area (roughly 1/3) in comparison to that in the Outside zone. \n",
    "\n",
    "On average, the Under Raincoat area accounted for more proportion of both total count and total dwell time in the evening than in the daytime. We notice that during these evening hours in the Under Raincoat area, the proportion of the free zone (i.e. where people tended to sit and stay) tended to be even greater in comparison to other hours. On the other hand in the other two areas, the proportion taken by the chair zone tended to decrease in comparison to daytime. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Events and User Specified Time Interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_dates = pd.read_csv('EventDates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "event_dates['Starting Time'] = event_dates['Starting Time'].apply(lambda x: dt.strptime(x, '%Y-%m-%dT%H:%M:%S'))\n",
    "event_dates['Ending Time'] = event_dates['Ending Time'].apply(lambda x: dt.strptime(x, '%Y-%m-%dT%H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column to indicate if there is an event in that hour\n",
    "for i in range(len(event_dates)):\n",
    "    # for device\n",
    "    feed_dwell_1h_df.loc[(feed_dwell_1h_df.time >= event_dates['Starting Time'][i]) &\n",
    "                         (feed_dwell_1h_df.time < event_dates['Ending Time'][i]), \n",
    "                         'Event'] = event_dates['Event'][i]\n",
    "    # for zone\n",
    "    zone_dwell_1h_df.loc[(zone_dwell_1h_df.time >= event_dates['Starting Time'][i]) &\n",
    "                         (zone_dwell_1h_df.time < event_dates['Ending Time'][i]), \n",
    "                         'Event'] = event_dates['Event'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def plot_dwell_pop_by_event(groupby, metric, chooseby, event, date):\n",
    "    '''\n",
    "    plot metric during a specified event or date\n",
    "    '''\n",
    "    df, _ = get_df(groupby, '1h')\n",
    "    date = pd.Timestamp(date)\n",
    "    \n",
    "    if groupby == 'device':\n",
    "        clr = None\n",
    "    else:\n",
    "        clr = zone_clrs\n",
    "    if chooseby == 'date':\n",
    "        df = df[df['date'] == date]\n",
    "    else:\n",
    "        df = df[df['Event'] == event]\n",
    "    \n",
    "    # part of the title\n",
    "    if chooseby == 'date':\n",
    "        at = \"on \" + str(date.date())\n",
    "    else:\n",
    "        at = \"at \"+ event\n",
    "    \n",
    "    fig = px.line(df, color = groupby, x='time', y=metric, color_discrete_sequence=clr,\n",
    "                  title=metric.replace('_', ' ').title() + \" \" + at + ' Grouped by ' + groupby.title())\n",
    "    fig = fig.update_traces(mode='lines')\n",
    "    fig.update_layout(xaxis_rangeslider_visible=True)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2aae5286ce1410380d795746eb776bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(RadioButtons(description='groupby', options=('device', 'zone'), value='device'), Dropdow…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = interact(plot_dwell_pop_by_event,\n",
    "             groupby=widgets.RadioButtons(options=['device', 'zone'], value='device'),\n",
    "             metric=widgets.Dropdown(options=metric_list, value='mean_dwell'),\n",
    "             chooseby=widgets.RadioButtons(options=['event', 'date'], value='event'),\n",
    "             date=widgets.DatePicker(value=pd.Timestamp('29/06/2019')),\n",
    "             event=widgets.Dropdown(options=event_dates.Event.tolist(), value=event_dates.Event.tolist()[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain heatmap for pedestrians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta, datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import calendar\n",
    "START_DATE = datetime(2019, 2, 20, 0, 0, 0)\n",
    "END_DATE = datetime(2020, 1, 11, 0, 0, 0)\n",
    "time_delta = relativedelta(days = +1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fundatmental functions to get the heatmap data \n",
    "def heatmap_query_gen(startTime: str, endTime: str, camera:int, obj:str):\n",
    "    '''\n",
    "    for generating heatmap query given time, device, and object\n",
    "    '''\n",
    "    heatmap_query = \"\"\"\n",
    "query {{\n",
    "  feedHeatmaps(\n",
    "    serialno: \"{0}\",\n",
    "    startTime:\"{1}\",\n",
    "    endTime:\"{2}\",\n",
    "    objClasses:[\"{3}\"],\n",
    "    timezone:\"America/New_York\") {{\n",
    "    edges {{\n",
    "      node {{\n",
    "        time\n",
    "        objClass\n",
    "        heatmap\n",
    "      }}\n",
    "    }}\n",
    "  }}\n",
    "}}\n",
    "\"\"\".format(camera, startTime, endTime,obj)\n",
    "    return heatmap_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_heatmap_data(camera: int, obj: str, start_times:list, end_times:list):\n",
    "    '''\n",
    "    get the heatmap matrix raw dataframe using  heatmap_query_gen as a helper\n",
    "    '''\n",
    "    heatmap_df = pd.DataFrame(columns = ['startTime', 'endTime', 'heatMap', 'obj'])\n",
    "    i = 0\n",
    "    while i < len(start_times):\n",
    "        heatmap_data = requests.post(url, \n",
    "                                     json={'query': heatmap_query_gen(start_times[i].strftime('%Y-%m-%dT%H:%M:%S'), \n",
    "                                                                      end_times[i].strftime('%Y-%m-%dT%H:%M:%S'), \n",
    "                                                                      camera, obj)},\n",
    "                                     headers = {'Authorization':token})\n",
    "        heatmap_json = heatmap_data.json()\n",
    "        if heatmap_json['data']:\n",
    "            if 'feedHeatmaps' in heatmap_json['data']:\n",
    "                heatmap = heatmap_json['data']['feedHeatmaps']['edges'][0]['node']['heatmap']\n",
    "                temp_df = pd.DataFrame({\"startTime\":start_times[i], \"endTime\":end_times[i], 'heatMap':heatmap, 'obj': obj})\n",
    "                heatmap_df = heatmap_df.append(temp_df, ignore_index = True)\n",
    "        i = i + 1\n",
    "    return heatmap_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_consecutive_times(start_time: datetime, end_time: datetime, interval: relativedelta):\n",
    "    '''\n",
    "    for generating consecutive datetime objects between start_time and end_time\n",
    "    '''\n",
    "    ## the first element in the list are the start times\n",
    "    time = [[], []]\n",
    "    current_time = start_time\n",
    "    while current_time < end_time:\n",
    "        time[0].append(current_time)\n",
    "        time[1].append(current_time + interval)\n",
    "        current_time = current_time + interval\n",
    "    return time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_heatmap_data(df):\n",
    "    '''\n",
    "    merge the raw heatmap data by day(time)\n",
    "    '''\n",
    "    return df.groupby(['startTime', 'endTime'])['heatMap'].apply(list).reset_index(name='heatMapMatrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def week_days(lis, weekday):\n",
    "    '''\n",
    "    This function is for generating a given weekday within a time period\n",
    "    '''\n",
    "    days = []\n",
    "    for day in lis:\n",
    "        if day.weekday() == weekday:\n",
    "            days.append(day)\n",
    "    return days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data to download: culmulative, event days(daily), highest dwell count days(top 20),  sundays \n",
    "device_dict = {'SWLSANDBOX1':'Streetscape', 'SWLSANDBOX2':'Under Raincoat', 'SWLSANDBOX3':'Outside'}\n",
    "device_ids = list(device_dict.keys())\n",
    "device_names = list(device_dict.values())\n",
    "\n",
    "time_delta = relativedelta(days = +1)\n",
    "all_time = generate_consecutive_times(START_DATE, END_DATE, time_delta)\n",
    "\n",
    "df, _ = get_df('device', '1d')\n",
    "\n",
    "df = df.sort_values(['count'], ascending=False)\n",
    "top_20_dwell_days = list(df[df.duplicated(['time'], keep=False)].head(20).time)\n",
    "\n",
    "# initialize time for each group\n",
    "# event\n",
    "event_days = [datetime(2019, 3, 2, 0, 0, 0), datetime(2019, 6, 29, 0, 0, 0), \n",
    "              datetime(2019, 8, 15, 0, 0, 0), datetime(2019, 9, 26, 0, 0, 0), \n",
    "              datetime(2019, 11, 20, 0, 0, 0), datetime(2019, 11, 21, 0, 0, 0), \n",
    "              datetime(2019, 11, 22, 0, 0, 0), datetime(2019, 11, 23, 0, 0, 0)] \n",
    "# sunday\n",
    "sunday_list = [week_days(all_time[0], 6), [i + time_delta for i in week_days(all_time[0], 6)]]\n",
    "\n",
    "# convert to time interval\n",
    "event_day_list = [event_days, [i + time_delta for i in event_days]]\n",
    "culmulative_list = [[START_DATE], [END_DATE]]\n",
    "top_20_dwell_days_list = [top_20_dwell_days, [i +  time_delta for i in top_20_dwell_days]]\n",
    "\n",
    "# groups\n",
    "day_name = ['event', 'sunday', 'high_count', 'culmulative']\n",
    "days_list = [event_day_list, sunday_list, top_20_dwell_days_list, culmulative_list]\n",
    "\n",
    "daily_heatmap_df = pd.DataFrame(columns = ['startTime', 'endTime', 'heatMapMatrix', 'day', 'device'])\n",
    "\n",
    "# download data\n",
    "for i in range(0,4):\n",
    "    for device in device_ids:\n",
    "        if i == 1:\n",
    "            sleep(5)\n",
    "        temp = daily_heatmap_data(get_heatmap_data(device, 'pedestrian', days_list[i][0], days_list[i][1]))\n",
    "        temp['day'] = day_name[i]\n",
    "        temp['device'] = device\n",
    "        daily_heatmap_df = daily_heatmap_df.append(temp)\n",
    "\n",
    "daily_heatmap_df = daily_heatmap_df.reset_index(drop = True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_daily_heatmap_df = pd.merge(daily_heatmap_df, df, left_on =['startTime', 'device'], \n",
    "                                   right_on = ['time', 'device_id'])\n",
    "\n",
    "merged_daily_heatmap_df = merged_daily_heatmap_df.drop(['startTime', 'endTime', 'device_x', 'mean_dwell', \n",
    "                                                        'max_dwell', 'device_id'], axis = 1).rename(\n",
    "                                                        columns={\"device_y\": \"device\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is a breif review of my heatmap for event days (with specific hours)\n",
    "event_dates = pd.read_csv('EventDates.csv')\n",
    "\n",
    "event_dates['Starting Time'] = event_dates.apply(lambda x: datetime.strptime(x['Starting Time'], '%Y-%m-%dT%H:%M:%S') \n",
    "                                                 ,axis=1)\n",
    "event_dates['Ending Time'] = event_dates.apply(lambda x: datetime.strptime(x['Ending Time'], '%Y-%m-%dT%H:%M:%S') ,axis=1)\n",
    "\n",
    "event_heatmap_df = pd.DataFrame(columns = ['startTime', 'endTime', 'heatMapMatrix', 'device'])\n",
    "for device in device_ids:\n",
    "    temp = daily_heatmap_data(get_heatmap_data(device, 'pedestrian', list(event_dates['Starting Time']), \n",
    "                                                        list(event_dates['Ending Time'])))\n",
    "    temp['device'] = device_dict[device]\n",
    "    temp = temp.rename(columns={\"startTime\": \"Starting Time\", \"endTime\": \"Ending Time\"})\n",
    "    event_heatmap_df = event_heatmap_df.append(temp, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_event_heatmap(camera):\n",
    "    '''\n",
    "    plots heatmap for events with eight subplots\n",
    "    '''\n",
    "    image = mpimg.imread('outside_sandbox.png')\n",
    "    if camera == \"Outside\":\n",
    "        image = mpimg.imread('outside_sandbox.png')\n",
    "    elif camera == \"Streetscape\":\n",
    "        image = mpimg.imread('streetscape_sandbox.png')\n",
    "    elif camera == \"Under Raincoat\":\n",
    "        image = mpimg.imread('underraincoat_sandbox.png')\n",
    "    \n",
    "    # define axis\n",
    "    fig, ax = plt.subplots(figsize=(16,10))\n",
    "    gs = gridspec.GridSpec(4, 17)\n",
    "    ax0 = plt.subplot(gs[0:2,0:4]) \n",
    "    ax1 = plt.subplot(gs[0:2,4:8])\n",
    "    ax2 = plt.subplot(gs[0:2,8:12]) \n",
    "    ax3 = plt.subplot(gs[0:2,12:16]) \n",
    "    ax4 = plt.subplot(gs[2:4,0:4]) \n",
    "    ax5 = plt.subplot(gs[2:4,4:8]) \n",
    "    ax6 = plt.subplot(gs[2:4,8:12]) \n",
    "    ax7 = plt.subplot(gs[2:4,12:16]) \n",
    "    ax8 = plt.subplot(gs[0:4,16])\n",
    "    \n",
    "    axes = [ax0, ax1, ax2, ax3, ax4, ax5, ax6, ax7]\n",
    "    \n",
    "    start_times = event_dates['Starting Time']\n",
    "    \n",
    "    end_times = event_dates['Ending Time']\n",
    "    \n",
    "    # loop over the 8 axes\n",
    "    for i in range(0,8):\n",
    "        data = list(event_heatmap_df[(event_heatmap_df['device'] == camera) & \n",
    "                                     (event_heatmap_df['Starting Time'] == start_times[i])]['heatMapMatrix'])\n",
    "        event_name = list(event_dates[event_dates['Starting Time'] == start_times[i]]['Event'])[0]\n",
    "        \n",
    "        # get data\n",
    "        if data:\n",
    "            data = data[0]\n",
    "            x = [i[0] for i in data]\n",
    "            y = [i[1] for i in data]\n",
    "            density = [i[2] for i in data]\n",
    "            axes[i].scatter(x=x,y=y, c=density, cmap = plt.cm.YlGnBu_r)\n",
    "        # show image\n",
    "        axes[i].imshow(image, aspect='auto')\n",
    "        axes[i].set_title(\"Event:{0}\\n on {1}\".format(event_name[0:20] + \n",
    "                                                      \"...\",str(start_times[i].year) + '.'+ \n",
    "                                                      str(start_times[i].month)+'.'+str(start_times[i].day)))\n",
    "        axes[i].axis('off')\n",
    "        \n",
    "    fig.colorbar(plt.cm.ScalarMappable(norm=mcolors.Normalize(), cmap=plt.cm.YlGnBu_r), cax=ax8)\n",
    "    ax8.set_ylabel(\"Color Bar of Density\", fontsize = 15)\n",
    "    fig.suptitle('Density Heatmap on Event Days under {0} Camera'.format(camera), y=1.05, fontsize=24)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This part is for design of plot_event_heatmap widget\n",
    "\n",
    "# A ToggleButtons for choosing camera\n",
    "Camera_Hbox_event = widgets.ToggleButtons(options=[('Outside',  \"Outside\"), ('Streetscape',\"Streetscape\") , \n",
    "                                             ('Under Raincoat', \"Under Raincoat\")], description='Camera:')\n",
    "\n",
    "# Widget for this function\n",
    "plot_event_heatmap_widget = widgets.interactive(plot_event_heatmap, {'manual': True},\n",
    "                                             camera = Camera_Hbox_event)\n",
    "\n",
    "## Get the button for running interaction\n",
    "button_event = plot_event_heatmap_widget.children[-2]\n",
    "\n",
    "## Get the output for running interaction\n",
    "output_event = plot_event_heatmap_widget.children[-1]\n",
    "\n",
    "## Store them vertically\n",
    "plot_cumulative_heatmap_widget = widgets.VBox(children=[Camera_Hbox_event, button_event, output_event])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00a1b1dc8bc8463492227c196363cbd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(ToggleButtons(description='Camera:', options=(('Outside', 'Outside'), ('Streetscape', 'Streetsc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_cumulative_heatmap_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize time data for loading the data\n",
    "# I want to load hourly data on 2019.6.29 as Initialization\n",
    "start_time = datetime(2019, 6, 29, 0, 0, 0)\n",
    "end_time = datetime(2019, 6, 30, 0, 0, 0)\n",
    "interval =  relativedelta(hours = +1)\n",
    "hour_interval = generate_consecutive_times(start_time, end_time, interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_column(data, date, camera, t):\n",
    "    '''\n",
    "    This is a simple wrapper function for creating columns\n",
    "    '''\n",
    "    data[\"date\"] = date\n",
    "    data[\"camera\"] = camera\n",
    "    data[\"type\"] = t\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hourly_heatmap_device(device_id, device_name):\n",
    "    '''\n",
    "    return df containing hourly heatmap data for the specified device\n",
    "    '''\n",
    "    # Initialize time data for loading the data\n",
    "    # I want to load hourly data on 2019.6.29 as Initialization\n",
    "    start_time = datetime(2019, 6, 29, 0, 0, 0)\n",
    "    end_time = datetime(2019, 6, 30, 0, 0, 0)\n",
    "    interval =  relativedelta(hours = +1)\n",
    "    hour_interval = generate_consecutive_times(start_time, end_time, interval)\n",
    "\n",
    "    df = daily_heatmap_data(get_heatmap_data(device_id, 'pedestrian', hour_interval[0], hour_interval[1]))\n",
    "    df = add_column(df, datetime(2019, 6, 29, 0, 0, 0), device_name, \"pedestrian\")\n",
    "    \n",
    "    ## Loading event hourly heatmap data \n",
    "    start_time = datetime(2019, 6, 29, 0, 0, 0)\n",
    "    \n",
    "    # loop over event day\n",
    "    for day in event_days:\n",
    "        if day != start_time:\n",
    "            start_time = day\n",
    "            end_time = start_time + relativedelta(days = +1)\n",
    "            hour_interval = generate_consecutive_times(start_time, end_time, interval)\n",
    "            temp = add_column(daily_heatmap_data(get_heatmap_data(device_id, 'pedestrian', \n",
    "                                                                  hour_interval[0], hour_interval[1])), start_time,  \n",
    "                              device_name, 'pedestrian')\n",
    "            df = df.append(temp, sort=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "streetscape_heatmap_pedestrian_event_days = get_hourly_heatmap_device('SWLSANDBOX1', 'streetscape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lsxna\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\frame.py:7138: FutureWarning:\n",
      "\n",
      "Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "underraincoat_heatmap_pedestrian_event_days = get_hourly_heatmap_device('SWLSANDBOX2', 'underraincoat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "outside_heatmap_pedestrian_event_days = get_hourly_heatmap_device('SWLSANDBOX3', 'outside')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is a helper function for getting the data for plotting hourly heatmap\n",
    "def event_hour_data_helper(camera, percentile, time):\n",
    "    '''\n",
    "    This is a simple helper function to get the data\n",
    "    camera is required to be \"Outside Camera\" or  \"StreetScape Camera\" or  \"UnderRainCoat Camera\"\n",
    "    percentile is required to be an integer between 0 and 100\n",
    "    time is required to be a datetime object on event days\n",
    "    Return Value for this function will be like [[1, 3, ...],[2, 1, ...],[12, 0.2,...]] \n",
    "    A list containing 3 sublists the first represent x, second for y, third for density, they have to be in the same length\n",
    "    '''\n",
    "    # choose df\n",
    "    data = []\n",
    "    if camera == \"Outside Camera\":\n",
    "        data = outside_heatmap_pedestrian_event_days\n",
    "    elif camera == \"StreetScape Camera\":\n",
    "        data = streetscape_heatmap_pedestrian_event_days\n",
    "    elif camera == \"UnderRainCoat Camera\":\n",
    "        data = underraincoat_heatmap_pedestrian_event_days\n",
    "        \n",
    "    data = list(data[data['startTime'] == time]['heatMapMatrix'])\n",
    "    if data:\n",
    "        p = np.percentile([i[2] for i in data[0]], percentile)\n",
    "        filtered = list(filter(lambda x : x[2] >= p, data[0]))\n",
    "        x = [i[0] for i in filtered] \n",
    "        y = [i[1] for i in filtered]\n",
    "        density = [i[2] for i in filtered]\n",
    "        data = [x, y, density]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "## heatmap_animation_hour(\"StreetScape Camera\", start_time, 20, 12)\n",
    "## User is able to select the event day, percentile,\n",
    "def heatmap_animation_hour(camera: str, day: datetime, percentile: int, hour: int):\n",
    "    '''\n",
    "    This is a function for plotting hourly heatmap on event days\n",
    "    day is required to be one of the event days\n",
    "    camera is required to be \"Outside Camera\" or  \"StreetScape Camera\" or  \"UnderRainCoat Camera\"\n",
    "    percentile is required to be an integer between 0 and 100\n",
    "    hour is required to be an interger between 0 to 23\n",
    "    The function will plot a heatmap given the day and hour, only keeps the data points above the percentile\n",
    "    '''\n",
    "    hour_interval =  relativedelta(hours = +1)\n",
    "    fig, ax = plt.subplots(figsize=(15,10))\n",
    "    \n",
    "    # Setting Background Image\n",
    "    if camera == \"Outside Camera\":\n",
    "        image = mpimg.imread('outside_sandbox.png')\n",
    "    elif camera == \"StreetScape Camera\":\n",
    "        image = mpimg.imread('streetscape_sandbox.png')\n",
    "    elif camera == \"UnderRainCoat Camera\":\n",
    "        image = mpimg.imread('underraincoat_sandbox.png')\n",
    "        \n",
    "    # We find the time through date + hour\n",
    "    day = day.date()\n",
    "    time = day+ hour_interval*hour\n",
    "    data = event_hour_data_helper(camera, percentile, time)\n",
    "    if data:\n",
    "        x = data[0]\n",
    "        y = data[1]\n",
    "        density = data[2]\n",
    "        ax.scatter(x, y, c= density, s=1, cmap= plt.cm.YlGnBu_r)\n",
    "        \n",
    "    # plot and labels\n",
    "    ax.imshow(image, aspect='auto')\n",
    "    ax.set_title(\"Hourly Heatmap Animation on {0}.{1}.{2} hour:{3}\".format(day.year, day.month, day.day, hour), \n",
    "                 fontsize = 24, y = 1.01)\n",
    "    ax.axis('off')\n",
    "    fig.colorbar(plt.cm.ScalarMappable(norm=mcolors.Normalize(), cmap=plt.cm.YlGnBu_r))\n",
    "    ax.text(750, 300, s =\"Color Bar of Density\", fontsize = 15,rotation=90)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is part is for design of widget for 'heatmap_animation_hour'\n",
    "## This is a play widget to display the hourly heatmap on event days automatically\n",
    "play= widgets.Play(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=23,\n",
    "    step=1,\n",
    "    interval=7000, # Notice that interval here is 7000ms, since it takes time to load heatmap data to the image\n",
    "    description=\"Press play\",\n",
    "    disabled=False\n",
    ")\n",
    "## This is a slider widget to change the hour value\n",
    "hour_slider = widgets.IntSlider(value=0,min=0,max=23,step=1,description='Hour:')\n",
    "# We link slider value with the player\n",
    "link = widgets.jslink((play, 'value'), (hour_slider, 'value'))\n",
    "# We show these widgets in a horizontal box\n",
    "hour_player= widgets.HBox([play, hour_slider])\n",
    "\n",
    "    \n",
    "## This is a dropdown widget for selecting day\n",
    "Day_time_drop = widgets.Dropdown(options=list(set(zip(list(event_dates.Event), \n",
    "                                                      list(event_dates['Starting Time'])))), description='Event:')\n",
    "## This is a ToggleButton widget for selecting camera\n",
    "Camera_Hbox = widgets.ToggleButtons(options=[('Outside',  \"Outside Camera\"), ('Streetscape',\"StreetScape Camera\") , \n",
    "                                             ('Under Raincoat', \"UnderRainCoat Camera\")], description='Camera:')\n",
    "## This is a intslider widget for selecting percentile you want to use\n",
    "percentile_slider = widgets.IntSlider(min=0, max=100, step=5, value=0)\n",
    "## Setting widget for each variable\n",
    "heatmap_animation_hour_widget = widgets.interactive(heatmap_animation_hour,\n",
    "                                             camera = Camera_Hbox,\n",
    "                                             day = Day_time_drop,\n",
    "                                             percentile = percentile_slider,\n",
    "                                             hour = hour_slider,continuous_update=False)\n",
    "## Get the output of the widget\n",
    "output_a = heatmap_animation_hour_widget.children[-1]\n",
    "\n",
    "## Rearrange the widgets in a vertical way\n",
    "tab1 =  widgets.VBox(children=[Camera_Hbox,\n",
    "                      Day_time_drop,\n",
    "                    percentile_slider,\n",
    "                      hour_player])\n",
    "## Display output and widget\n",
    "heatmap_animation_hour_widget = widgets.VBox(children=[tab1, output_a]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45c392c22a874df2b53036c6eb54b860",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(ToggleButtons(description='Camera:', options=(('Outside', 'Outside Camera'), ('S…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "heatmap_animation_hour_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "## functions to generate cumulative heatmap matrix\n",
    "def weight_matrix(matrix, factor):\n",
    "    '''\n",
    "    This function is a helper function to generate weighted heatmap matrix\n",
    "    It will return the gievn heatmap matrix with density multiply the factor\n",
    "    '''\n",
    "    new_density = [i[2]*factor for i in matrix]\n",
    "    temp =  [[matrix[i][0], matrix[i][1], new_density[i]] for i in range(len(matrix))]\n",
    "    \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This function generate data for summation of heatmap matrix\n",
    "def culmulative_heat_map_data_generator(days, data, camera):\n",
    "    '''\n",
    "    This function is a helper function to generate weighted heatmap matrix\n",
    "    It will takes multiple heatmap, store them into one big list, and return\n",
    "    '''\n",
    "    culmulative_data_lis = []\n",
    "    for day in days:\n",
    "        daily_data = list(data[(data['time'] == day) & (data['device'] == camera)]['weighted_heatMapMatrix'])\n",
    "        if daily_data:\n",
    "            culmulative_data_lis.append(daily_data[0])\n",
    "    return culmulative_data_lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def culmulative_heat_map_data(data):\n",
    "    '''\n",
    "    This function is a helper function to generate weighted heatmap matrix\n",
    "    It will takes a list containing heatmaps, combine them into a single heatmap\n",
    "    '''\n",
    "    ## This is dictionary takes coordinates as keys, take density as value\n",
    "    culmulative_data_dic = {}\n",
    "    ## This is list stores the finalized heatmap\n",
    "    culmulative_data_lis = []\n",
    "    for daily_data in data:\n",
    "        for coordinate_data in daily_data:\n",
    "            coordinate = (coordinate_data[0], coordinate_data[1])\n",
    "            if coordinate not in culmulative_data_dic:\n",
    "                culmulative_data_dic[coordinate] = coordinate_data[2]\n",
    "            else:\n",
    "                culmulative_data_dic[coordinate] += coordinate_data[2]\n",
    "    for coordinate in list(culmulative_data_dic.keys()):\n",
    "        culmulative_data_lis.append([coordinate[0], coordinate[1], culmulative_data_dic[coordinate]])\n",
    "    return culmulative_data_lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add weighted heatmap matrix for three dataframes \n",
    "## Merge counts with heatmap first\n",
    "merged_daily_heatmap_df[\"weighted_heatMapMatrix\"] = \\\n",
    "    merged_daily_heatmap_df.apply(lambda x: weight_matrix(x['heatMapMatrix'], x['count']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quantiled_data(data, percentile, form):\n",
    "    '''\n",
    "    This function is a helper function to get the quantiled data in two ways\n",
    "    If form variable is True, it will return [[x coordinates], [y coordinates], [density]]\n",
    "    '''\n",
    "    p = np.percentile([i[2] for i in data], percentile)\n",
    "    filtered = list(filter(lambda x : x[2] >= p, data))\n",
    "    if form:\n",
    "        x = [i[0] for i in filtered] \n",
    "        y = [i[1] for i in filtered]\n",
    "        density = [i[2] for i in filtered]\n",
    "        return [x, y, density]\n",
    "    else:\n",
    "        return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This function generate quantiled x,y coordinates, used for clustering\n",
    "def get_quantiled_data_coordinate(data, percentile):\n",
    "    '''\n",
    "    This function is a helper function to get the coordinates of quantiled data\n",
    "    It will return all coordinates of data points above percentile \n",
    "    '''\n",
    "    p = np.percentile([i[2] for i in data], percentile)\n",
    "    filtered = list(filter(lambda x : x[2] >= p, data))\n",
    "    x = [i[0] for i in filtered] \n",
    "    y = [i[1] for i in filtered]\n",
    "    density = [i[2] for i in filtered]\n",
    "    quantiled_data = []\n",
    "    for i in range(len(x)):\n",
    "        quantiled_data.append([x[i], y[i]])\n",
    "    return quantiled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cumulative_heatmap_data_helper(camera:str, plot:str, quantile:int, form):\n",
    "    '''\n",
    "    This function is a helper function to get the dataframe based on gievn camera and days(plot)\n",
    "    '''\n",
    "    # get data\n",
    "    data = []\n",
    "    if plot == \"Event Days\":\n",
    "        data = culmulative_heat_map_data(culmulative_heat_map_data_generator\n",
    "                                         (event_days, merged_daily_heatmap_df,camera))\n",
    "    elif plot == \"All the Days\":\n",
    "        data = list(merged_daily_heatmap_df[(merged_daily_heatmap_df['device'] == camera) & \n",
    "                                            (merged_daily_heatmap_df['day'] == 'culmulative')]['heatMapMatrix'])[0]\n",
    "    elif plot == \"Sundays\":\n",
    "        data = culmulative_heat_map_data(culmulative_heat_map_data_generator(week_days(all_time[0], 6), \n",
    "                                                                             merged_daily_heatmap_df,camera))\n",
    "    elif plot == \"High Dwell Count Days\":\n",
    "          data =  culmulative_heat_map_data(culmulative_heat_map_data_generator\n",
    "                                            (top_20_dwell_days, merged_daily_heatmap_df,camera))\n",
    "    \n",
    "    # calculate density        \n",
    "    total_density = sum(i[2]  for i in data)\n",
    "    data = get_quantiled_data(data, quantile, form)\n",
    "    quantiled_density = sum(data[2])\n",
    "    return (data, [quantiled_density, total_density-quantiled_density])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_circle(radius, center, coordinate):\n",
    "    '''\n",
    "    This function is a helper function to check if a coordinate is in the circle\n",
    "    '''\n",
    "    return ((center[0]- coordinate[0])**2 + (center[1]- coordinate[1])**2) < radius**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cumulative_heatmap(camera, plot1, plot2, quantile1, quantile2):\n",
    "    '''\n",
    "    This is a function for plotting culmulative heatmap on event days, all days...\n",
    "    Plot1 is the days you want to plot on the above plot \n",
    "    Plot2 is for the below plot\n",
    "    camera is required to be \"Outside Camera\" or  \"StreetScape Camera\" or  \"UnderRainCoat Camera\"\n",
    "    quantile is required to be an integer between 0 and 100\n",
    "    The function will plot two culmulative heatmaps given the days and camera, only keeps the data points above the quantile\n",
    "    \n",
    "    Also, it will plot four pie charts. They indicates the proportion of data points on the plot\n",
    "    The proportion of total density of data points on the plot\n",
    "    '''\n",
    "    \n",
    "    # Setting Background Image\n",
    "    if camera == \"Outside\":\n",
    "        image = mpimg.imread('outside_sandbox.png')\n",
    "    elif camera == \"Streetscape\":\n",
    "        image = mpimg.imread('streetscape_sandbox.png')\n",
    "    elif camera == \"Under Raincoat\":\n",
    "        image = mpimg.imread('underraincoat_sandbox.png')\n",
    "      \n",
    "    # Get the data for two plots\n",
    "    temp1 =  cumulative_heatmap_data_helper(camera, plot1, quantile1, True)\n",
    "    temp2 = cumulative_heatmap_data_helper(camera, plot2, quantile2, True)\n",
    "    \n",
    "    # Divide them into x, y, density lists\n",
    "    data1 = temp1[0]\n",
    "    pie1 = temp1[1]\n",
    "    data2 = temp2[0]\n",
    "    pie2 = temp2[1]\n",
    "    \n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(16,10))\n",
    "    gs = gridspec.GridSpec(8, 13)\n",
    "    ax0 = plt.subplot(gs[0:4,0:8]) # upper heatmap\n",
    "    ax1 = plt.subplot(gs[4:8,0:8]) # lower heatmap\n",
    "    ax2 = plt.subplot(gs[0:2,9:13]) # 1st pie chart\n",
    "    ax3 = plt.subplot(gs[2:4,9:13]) # 2nd pie chart\n",
    "    ax4 = plt.subplot(gs[4:6,9:13]) # 3rd pie chart\n",
    "    ax5 = plt.subplot(gs[6:8,9:13]) # 4th pie chart\n",
    "    ax6 = plt.subplot(gs[0:8,8])\n",
    "    \n",
    "    # Upper heatmap\n",
    "    ax0.scatter(data1[0], data1[1], c = data1[2], cmap = plt.cm.YlGnBu_r, s = 0.1)\n",
    "    ax0.imshow(image, aspect='auto')\n",
    "    ax0.set_title(\"Heatmap for {0} on {1} ({2} Percentile)\".format(camera, plot1, quantile1))\n",
    "    ax0.axis('off')\n",
    "    \n",
    "    # Lower heatmap\n",
    "    ax1.scatter(data2[0], data2[1], c = data2[2], cmap = plt.cm.YlGnBu_r, s = 0.1)\n",
    "    ax1.imshow(image, aspect='auto')\n",
    "    ax1.set_title(\"Heatmap for {0} on {1} ({2} Percentile)\".format(camera, plot2, quantile2))\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    # Labels, title and colors for pie charts\n",
    "    label1 = ['Points on the plot', 'Other Points']\n",
    "    title1 = \"Density Proportion for {0}\".format(plot1)\n",
    "    label2 =  ['Points on the plot', 'Other Points']\n",
    "    title2 =  \"Proportion of Number of Points for {0}\".format(plot1)\n",
    "    label3 = ['Points on the plot', 'Other Points']\n",
    "    title3 = \"Density Proportion of for {0}\".format(plot2) \n",
    "    label4 =  ['Points on the plot', 'Other Points']\n",
    "    title4 =  \"Proportion of Number of Points for {0} \".format(plot2)\n",
    "    colors=[\"lightskyblue\", \"lightcoral\"]\n",
    "    \n",
    "    # Plot pie charts and set their titles and legends\n",
    "    wedges, texts, autotexts = ax2.pie(pie1, autopct='%1.1f%%', colors = colors)\n",
    "    ax2.legend(wedges, label1,  loc=\"center left\",bbox_to_anchor=(1, 0, 0.5, 1))\n",
    "    ax2.set_title(title1)\n",
    "    \n",
    "    wedges, texts, autotexts= ax3.pie([100-quantile1, quantile1], autopct='%1.1f%%', colors = colors)\n",
    "    ax3.legend(wedges, label2,  loc=\"center left\",bbox_to_anchor=(1, 0, 0.5, 1))\n",
    "    ax3.set_title(title2)\n",
    "    \n",
    "    wedges, texts, autotexts= ax5.pie([100-quantile2, quantile2], autopct='%1.1f%%', colors = colors)\n",
    "    ax5.legend(wedges,label4, loc=\"center left\",bbox_to_anchor=(1, 0, 0.5, 1))\n",
    "    ax5.set_title(title4)\n",
    "    \n",
    "    ax4.set_title(title3)\n",
    "    wedges, texts, autotexts = ax4.pie(pie2,autopct='%1.1f%%', colors = colors)\n",
    "    ax4.legend(wedges,label3, loc=\"center left\",bbox_to_anchor=(1, 0, 0.5, 1))\n",
    "    \n",
    "    fig.colorbar(plt.cm.ScalarMappable(norm=mcolors.Normalize(), cmap=plt.cm.YlGnBu_r), cax=ax6)\n",
    "    \n",
    "    ax6.set_ylabel(\"Color Bar of Density\", fontsize = 15)\n",
    "    \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is part is for design of widget for 'plot_cumulative_heatmap'\n",
    "\n",
    "## Make sure description will not be shorten\n",
    "style = {'description_width': 'initial'}\n",
    "\n",
    "## Two dropdowns for selecting days\n",
    "Plot1_Drop = widgets.Dropdown(options=[\"Event Days\",\"All the Days\", \"Sundays\", \"High Dwell Count Days\"], \n",
    "                              description='Time (first plot): ', style = style)\n",
    "Plot2_Drop = widgets.Dropdown(options=[\"Event Days\",\"All the Days\", \"Sundays\", \"High Dwell Count Days\"], \n",
    "                              description='Time (second plot):', style = style)\n",
    "\n",
    "## Two Intslider for selecting percentiles\n",
    "Plot1_quantile  = widgets.IntSlider(min=0, max=100, step=1, value=50, \n",
    "                                    description='Percentile (first plot): ',style = style)\n",
    "Plot2_quantile = widgets.IntSlider(min=0, max=100, step=1, value=50, \n",
    "                                   description='Percentile (second plot): ',style = style)\n",
    "\n",
    "## Store them seperately in horizontal boxes\n",
    "Plot1_Hbox = widgets.HBox(children=[Plot1_Drop, Plot1_quantile], style = style)\n",
    "Plot2_Hbox = widgets.HBox(children=[Plot2_Drop, Plot2_quantile], style = style)\n",
    "Camera_Hbox = widgets.ToggleButtons(options=[('Outside',  \"Outside\"), ('Streetscape',\"Streetscape\"), \n",
    "                                             ('Under Raincoat', \"Under Raincoat\")], description='Camera:')\n",
    "\n",
    "## Set the widgets to vairables of functions\n",
    "plot_cumulative_heatmap_widget = widgets.interactive(plot_cumulative_heatmap, {'manual': True},\n",
    "                                             camera = Camera_Hbox,\n",
    "                                             plot1 = Plot1_Drop,\n",
    "                                             plot2 = Plot2_Drop,\n",
    "                                             quantile1 = Plot1_quantile,\n",
    "                                             quantile2 = Plot2_quantile)\n",
    "\n",
    "## Get the button for running interaction\n",
    "button1 = plot_cumulative_heatmap_widget.children[-2]\n",
    "\n",
    "## Get the output for running interaction\n",
    "output1 = plot_cumulative_heatmap_widget.children[-1]\n",
    "\n",
    "## Store them vertically\n",
    "tab1 = widgets.VBox(children=[Camera_Hbox,\n",
    "                      Plot1_Hbox,\n",
    "                    Plot2_Hbox,button1])\n",
    "\n",
    "plot_cumulative_heatmap_widget = widgets.VBox(children=[tab1, output1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5ad15e4787c420181c4ea43787e14a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(ToggleButtons(description='Camera:', options=(('Outside', 'Outside'), ('Streetsc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_cumulative_heatmap_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans, KMeans\n",
    "import math\n",
    "\n",
    "def plot_cumulative_heatmap_points(camera, plot1, plot2, radius, coordinate_x, coordinate_y, show_scatter):\n",
    "    '''\n",
    "    plots two subplots with a red circle as specified by the coordinates and radius\n",
    "    '''\n",
    "    # Setting Coordinates\n",
    "    coordinate = (coordinate_x,coordinate_y)\n",
    "    # Setting Background Image\n",
    "    if camera == \"Outside\":\n",
    "        image = mpimg.imread('outside_sandbox.png')\n",
    "    elif camera == \"Streetscape\":\n",
    "        image = mpimg.imread('streetscape_sandbox.png')\n",
    "    elif camera == \"Under Raincoat\":\n",
    "        image = mpimg.imread('underraincoat_sandbox.png')\n",
    "\n",
    "    # Divide the image into four parts\n",
    "    fig, ax = plt.subplots(figsize=(16,10))\n",
    "    gs = gridspec.GridSpec(8, 13)\n",
    "    ax0 = plt.subplot(gs[0:4,0:8]) # upper heatmap\n",
    "    ax1 = plt.subplot(gs[4:8,0:8]) # lower heatmap\n",
    "    ax2 = plt.subplot(gs[0:2,9:13]) # 1st pie chart\n",
    "    ax3 = plt.subplot(gs[2:4,9:13])# 2nd pie chart\n",
    "    ax4 = plt.subplot(gs[4:6,9:13])# 3rd pie chart\n",
    "    ax5 = plt.subplot(gs[6:8,9:13])# 4th pie chart\n",
    "    ax6 =  plt.subplot(gs[0:8,8])\n",
    "    \n",
    "    # Calculate the Area around the circle\n",
    "    area = math.pi*(radius*radius) # limitation, circle may not in reactangle\n",
    "    total_area = 500 * 650\n",
    "    \n",
    "    # label and colors for pie charts\n",
    "    label = [\"Inside the circle\", \"Outside the circle\"]\n",
    "    colors=[\"orange\", \"lightskyblue\"]\n",
    "    \n",
    "    for plot, ax, density_ax, prop_ax in zip([plot1, plot2], [ax0, ax1], [ax2, ax4], [ax3, ax5]):\n",
    "        data =  cumulative_heatmap_data_helper(camera, plot, 80, False)[0]\n",
    "        \n",
    "        # Show the scatter plot \n",
    "        if show_scatter:\n",
    "            temp =  cumulative_heatmap_data_helper(camera, plot, 0, True)\n",
    "            data_scatter = temp[0]\n",
    "            ax.scatter(data_scatter[0], data_scatter[1], c = data_scatter[2], cmap = plt.cm.YlGnBu_r, s = 0.1)\n",
    "            \n",
    "        circle = plt.Circle(coordinate, radius, color='orange', fill=False,lw=5 )\n",
    "        ax.add_artist(circle)\n",
    "        ax.imshow(image, aspect='auto')\n",
    "        ax.set_title(\"{0} on {1} \".format(camera, plot))\n",
    "        \n",
    "        # Calculate the density inside the circles\n",
    "        circle_density = 0\n",
    "        total_density = 0\n",
    "        for coordinates in data:\n",
    "            total_density = total_density + coordinates[2]\n",
    "            if check_circle(radius,coordinate,(coordinates[0],coordinates[1])):\n",
    "                circle_density = circle_density + coordinates[2]\n",
    "        \n",
    "        # pie chart data\n",
    "        pie1 = [circle_density, total_density - circle_density]\n",
    "        pie2 = [area, total_area-area]\n",
    "        \n",
    "        # Deal with pie charts\n",
    "        # upper\n",
    "        wedges, texts, autotexts = density_ax.pie(pie1, autopct='%1.1f%%', colors = colors)\n",
    "        density_ax.legend(wedges, label, loc=\"center left\", bbox_to_anchor=(1, 0, 0.5, 1))\n",
    "        density_ax.set_title(\"Density inside Circle for {0}\".format(plot))\n",
    "        # lower\n",
    "        wedges, texts, autotexts = prop_ax.pie(pie2, autopct='%1.1f%%', colors = colors)\n",
    "        prop_ax.legend(wedges, label, loc=\"center left\", bbox_to_anchor=(1, 0, 0.5, 1))\n",
    "        prop_ax.set_title(\"Proportion of Area\")\n",
    "    \n",
    "    fig.colorbar(plt.cm.ScalarMappable(norm=mcolors.Normalize(), cmap=plt.cm.YlGnBu_r), cax=ax6)\n",
    "    ax6.set_ylabel(\"Color Bar of Density\", fontsize = 15)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is part is for design of widget for 'plot_cumulative_heatmap_points'\n",
    "\n",
    "## This is a ToggleButton widget for selecting camera\n",
    "Camera_Hbox = widgets.ToggleButtons(\n",
    "    options=[('Outside',  \"Outside\"), ('Streetscape',\"Streetscape\") , ('Under Raincoat', \"Under Raincoat\")],\n",
    "    description='Camera:',\n",
    ")\n",
    "\n",
    "## They are two dropdowns widgets for choosing days\n",
    "Plot1_Drop_2 = widgets.Dropdown(options=[\"Event Days\",\"All the Days\", \"Sundays\", \"High Dwell Count Days\"], \n",
    "                                description='Time (first plot): ', style = style)\n",
    "Plot2_Drop_2 = widgets.Dropdown(options=[\"Event Days\",\"All the Days\", \"Sundays\", \"High Dwell Count Days\"], \n",
    "                                description='Time (second plot):', style = style)\n",
    "\n",
    "\n",
    "## They are two intslider widgets for the size and position of circle\n",
    "radius_slider = widgets.IntSlider(min=1, max=80, step=1, value=40, description='Radius of the circle:', style = style)\n",
    "x_coordinate_slider = widgets.IntSlider(min=30, max=600, step=1, value=300, \n",
    "                                        description='x coordinate of the center of the circle:',style = style, \n",
    "                                        layout=widgets.Layout(width='50%', height='30px'))\n",
    "y_coordinate_slider = widgets.IntSlider(min=30, max=450, step=1, value=200, \n",
    "                                        description='y coordinate of the center of the circle:', style = style,\n",
    "                                       layout=widgets.Layout(width='50%', height='30px'))\n",
    "\n",
    "## They are two checkpoints to show what to display on the plots\n",
    "show_scatter_box = widgets.Checkbox(value=False, description='Show Desired Lines(Heatmap)', disabled=False, \n",
    "                                    indent=False, style = style)\n",
    "\n",
    "## Set the widgets to vairables of functions\n",
    "plot_cumulative_heatmap_points_widget = widgets.interactive(plot_cumulative_heatmap_points, {'manual': True},\n",
    "                                         camera = Camera_Hbox, \n",
    "                                         plot1 = Plot1_Drop_2, \n",
    "                                         plot2 = Plot2_Drop_2,\n",
    "                                         radius = radius_slider,\n",
    "                                         coordinate_x = x_coordinate_slider,\n",
    "                                         coordinate_y = y_coordinate_slider,\n",
    "                                         show_scatter = show_scatter_box)\n",
    "\n",
    "## Rearrange the position of wiegets\n",
    "coordinate_Hbox = widgets.HBox(children=[x_coordinate_slider, y_coordinate_slider])\n",
    "Plot1_Hbox_1 = widgets.HBox(children=[Plot1_Drop_2])\n",
    "Plot1_Hbox_2 = widgets.HBox(children=[Plot2_Drop_2])\n",
    "Show= widgets.HBox(children=[show_scatter_box])\n",
    "vbox1 = widgets.VBox(children=[Camera_Hbox, Show, Plot1_Hbox_1, Plot1_Hbox_2])\n",
    "vbox2 = widgets.VBox(children=[coordinate_Hbox, radius_slider])\n",
    "\n",
    "# tabs\n",
    "tab = widgets.Tab(children=[vbox1, vbox2])\n",
    "tab.set_title(0, 'Plot')\n",
    "tab.set_title(1, 'Spot Selection')\n",
    "\n",
    "# buttons\n",
    "button2 = plot_cumulative_heatmap_points_widget.children[-2]\n",
    "output = plot_cumulative_heatmap_points_widget.children[-1]\n",
    "tab2 = widgets.VBox(children=[tab, button2])\n",
    "plot_cumulative_heatmap_points_widget_rearrange = widgets.VBox(children = [tab2, output]) \n",
    "plot_cumulative_heatmap_points_widget =plot_cumulative_heatmap_points_widget_rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66f6119466b7464e9d7d37da5da24fcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(Tab(children=(VBox(children=(ToggleButtons(description='Camera:', options=(('Out…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_cumulative_heatmap_points_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: merge with the previous func\n",
    "\n",
    "def get_hourly_dwell(func, ID, interval, startTime, endTime):\n",
    "    '''\n",
    "    func is either feedDwellTimeDistribution or zoneDwellTimeDistribution\n",
    "    '''\n",
    "    startTime_str = startTime.strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "    endTime_str = endTime.strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "    \n",
    "    if func == 'feedDwellTimeDistribution':\n",
    "        arg = 'serialnos: \"{0}\"'.format(ID)\n",
    "    else:\n",
    "        arg = 'zoneIds: {0}'.format(ID)\n",
    "        \n",
    "    query = \"\"\"\n",
    "    query {{\n",
    "        {0}(\n",
    "        {1},\n",
    "        startTime: \"{2}\",\n",
    "        endTime: \"{3}\",\n",
    "        timezone: \"America/New_York\",\n",
    "        objClasses: [\"pedestrian\", \"car\"],\n",
    "        interval: \"{4}\"\n",
    "        ){{\n",
    "        edges {{\n",
    "          node {{\n",
    "            time\n",
    "            objClass\n",
    "            pct100\n",
    "            pct75\n",
    "            pct50\n",
    "            pct25\n",
    "            mean\n",
    "            count\n",
    "          }}\n",
    "        }}\n",
    "      }}\n",
    "    }}\n",
    "    \"\"\".format(func, arg, startTime_str, endTime_str,  interval)\n",
    "\n",
    "    dwell = requests.post(url, json={'query': query}, \n",
    "                           headers = {'Authorization':token})\n",
    "    \n",
    "    df = pd.DataFrame([x['node'] for x in dwell.json()['data'][func]['edges']])\n",
    "    if func == 'feedDwellTimeDistribution':\n",
    "        df['device'] = ID\n",
    "    else:\n",
    "        df['zone'] = ID\n",
    "    df['time'] = [datetime.strptime(i[:-6], \"%Y-%m-%dT%H:%M:%S\") for i in list(df['time'])]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the days that we want to investigate conflict zone, we choose the days with 10 highest count of cars\n",
    "dwell_data_allobj = get_hourly_dwell('feedDwellTimeDistribution','SWLSANDBOX2' , '1d', START_DATE, END_DATE)\n",
    "\n",
    "dwell_data_car = dwell_data_allobj[dwell_data_allobj['objClass'] == 'car'].sort_values(by='count', ascending=False)\n",
    "\n",
    "high_traffic_day_list = list(dwell_data_car.sort_values(by='count', ascending=False)['time'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Then, we get the dwell data of dwell data of these days\n",
    "time_delta_hour = time_delta = relativedelta(hours = +1)\n",
    "dwell_data_traffic_day = pd.concat([get_hourly_dwell('feedDwellTimeDistribution','SWLSANDBOX2', '1h', \n",
    "                                                     x+7*time_delta_hour, x+23*time_delta_hour) \n",
    "                                    for x in high_traffic_day_list])\n",
    "\n",
    "dwell_data_traffic_day =  dwell_data_traffic_day.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "column_names = [\"startTime\", \"endTime\", \"heatMapMatrix\", \"objClass\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_high_traffic_heatmap(obj):\n",
    "    '''\n",
    "    obj is either 'car' or 'pedestrian'\n",
    "    returns a df containing heatmap data\n",
    "    '''\n",
    "    df = pd.DataFrame(columns = column_names)\n",
    "    \n",
    "    for day in high_traffic_day_list:\n",
    "        \n",
    "        time_delta_hour = relativedelta(hours = +1)\n",
    "        start_hour = day + time_delta_hour*7\n",
    "        end_hour = day + time_delta_hour*23\n",
    "        \n",
    "        interval = generate_consecutive_times(start_hour, end_hour, time_delta_hour)\n",
    "        temp = daily_heatmap_data(get_heatmap_data('SWLSANDBOX2', obj, interval[0], interval[1]))\n",
    "        temp['objClass'] = obj\n",
    "        df = pd.concat([temp, df])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get Heatmap data of car these days based on hour\n",
    "high_traffic_day_car_heatmap = get_high_traffic_heatmap('car')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get Heatmap data of pedestrian these days based on hour\n",
    "high_traffic_day_pedestrian_heatmap = get_high_traffic_heatmap('pedestrian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge two dataframes \n",
    "high_traffic_day_heatmap = pd.concat([high_traffic_day_car_heatmap, high_traffic_day_pedestrian_heatmap])\n",
    "# merge and drop\n",
    "high_traffic_day_merged = pd.merge(high_traffic_day_heatmap, dwell_data_traffic_day, \n",
    "                                   left_on = [\"startTime\", \"objClass\"], \n",
    "                                   right_on = [\"time\", \"objClass\"]).drop(\n",
    "                                   [\"endTime\",  \"startTime\", \"pct75\", \"pct25\", \"device\", \"pct100\", \"mean\",\"pct50\"], \n",
    "                                   axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find weighted heatmap matrix\n",
    "high_traffic_day_merged[\"WeightedheatMapMatrix\"] = \\\n",
    "    high_traffic_day_merged.apply(lambda x: weight_matrix(x['heatMapMatrix'], x['count']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Seperate two dataframes based on objclass\n",
    "high_traffic_day_car_merged = \\\n",
    "    high_traffic_day_merged[high_traffic_day_merged['objClass'] == 'car']\\\n",
    "    .drop([\"heatMapMatrix\", \"objClass\"], axis = 1)\n",
    "high_traffic_day_car_merged.rename(columns={\"WeightedheatMapMatrix\": \"carWeightedheatMapMatrix\", \"count\": \"carCount\"}, \n",
    "                                   inplace = True)\n",
    "\n",
    "high_traffic_day_pedestrian_merged = \\\n",
    "    high_traffic_day_merged[high_traffic_day_merged['objClass'] == 'pedestrian']\\\n",
    "    .drop([\"heatMapMatrix\", \"objClass\"], axis = 1)\n",
    "high_traffic_day_pedestrian_merged.rename(columns={\"WeightedheatMapMatrix\": \"pedestrianWeightedheatMapMatrix\", \n",
    "                                                   \"count\": \"pedestrianCount\"}, \n",
    "                                          inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_traffic_day_hourly_heatmap = \\\n",
    "    pd.merge(high_traffic_day_car_merged, high_traffic_day_pedestrian_merged, how = \"outer\", on =\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_distance(c1, c2):\n",
    "    return ((c1[0] - c2[0])**2 + (c1[1] - c2[1])**2)**(1/2)\n",
    "\n",
    "\n",
    "def calculate_conflicting_index(non_pd, pd):\n",
    "    '''\n",
    "    This is a function for calculating conflicting index of datapoints under the camera,\n",
    "    non_pd is the heatmap matrix for nonpedastrain objects,\n",
    "    pd is the heatmap matrix for nonpedastrain objects.\n",
    "    \n",
    "    The input matrix should be weighted.\n",
    "    For each non-pedestrian object, check pedestrian density around it with distance less than 50\n",
    "    Its conflicting index is proportional to density of objects, but has negative relationship with distance.\n",
    "    Therefore, the index is calculated by density of non_pd object at that point * (sum(density of pd objects/ distance))\n",
    "    For more information, see documentation.\n",
    "    '''\n",
    "    conflicting_index = []\n",
    "    if type(non_pd) == float:\n",
    "        return []\n",
    "    else:\n",
    "        if type(pd) == float:\n",
    "            return []\n",
    "        \n",
    "        for coordinate in non_pd:\n",
    "            index = 0\n",
    "            \n",
    "            for coordinate_p in pd:\n",
    "                distance = find_distance(coordinate[0:2], coordinate_p[0:2])\n",
    "                if distance < 1:\n",
    "                      index = index + coordinate[2]*coordinate_p[2]\n",
    "                elif distance < 50:\n",
    "                    index = index + coordinate[2]*coordinate_p[2]/distance\n",
    "                    \n",
    "            conflicting_index.append([coordinate[0], coordinate[1], index])\n",
    "        return conflicting_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_conflicting_index(lis):\n",
    "    '''\n",
    "    This is a helper function which sums up the density\n",
    "    '''\n",
    "    s = 0\n",
    "    for i in lis:\n",
    "        s = i[2] + s\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Caluclate conflictIndexMatrix for every time period\n",
    "high_traffic_day_hourly_heatmap['conflictIndexMatrix'] = \\\n",
    "    high_traffic_day_hourly_heatmap.apply(lambda x : calculate_conflicting_index(\n",
    "                                          x['carWeightedheatMapMatrix'],\n",
    "                                          x['pedestrianWeightedheatMapMatrix']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sum up the total conflictIndex in a given time period\n",
    "high_traffic_day_hourly_heatmap[\"conflict_index_total\"] = \\\n",
    "    [sum_conflicting_index(i) for i in list(high_traffic_day_hourly_heatmap['conflictIndexMatrix'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Group the data by hour\n",
    "high_traffic_day_hourly_heatmap['hour'] = [i.hour for i in high_traffic_day_hourly_heatmap[\"time\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "def lineplot_hour_conflicting(objclass, metric):# Create figure with secondary y-axis\n",
    "    fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "    \n",
    "    #check what objclass it comes from\n",
    "    obj = objclass + \"Count\"\n",
    "\n",
    "    # Add traces\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=list(high_traffic_day_hourly_heatmap.groupby(['hour']).sum()['conflict_index_total'].index),\n",
    "                   y=list(high_traffic_day_hourly_heatmap.groupby(['hour'])['conflict_index_total'].sum()), \n",
    "                   name=\"Cumulative Conflicting Index\"),\n",
    "        secondary_y=False,\n",
    "    )\n",
    "\n",
    "    # if metric is mean\n",
    "    if metric == \"mean\":\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=high_traffic_day_hourly_heatmap.groupby(['hour']).mean()[obj].index,\n",
    "                       y=list(high_traffic_day_hourly_heatmap.groupby(['hour'])[obj].mean()), \n",
    "                       name=\"{0} Count({1})\".format(objclass.title(), metric)),\n",
    "            secondary_y=True,\n",
    "        )\n",
    "    # if metric is median\n",
    "    if metric == \"median\":\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=high_traffic_day_hourly_heatmap.groupby(['hour']).median()[obj].index,\n",
    "                       y=list(high_traffic_day_hourly_heatmap.groupby(['hour'])[obj].median()), \n",
    "                       name=\"{0} Count({1})\".format(objclass.title(), metric)),\n",
    "            secondary_y=True,\n",
    "        )\n",
    "    # if metric is max\n",
    "    if metric == \"max\":\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=high_traffic_day_hourly_heatmap.groupby(['hour']).max()[obj].index,\n",
    "                       y=list(high_traffic_day_hourly_heatmap.groupby(['hour'])[obj].max()), \n",
    "                       name=\"{0} Count({1})\".format(objclass.title(), metric)),\n",
    "            secondary_y=True,\n",
    "        )\n",
    "    # Add figure title\n",
    "    fig.update_layout(\n",
    "        title_text=\"Cumulative Conflicting Index (hour)\"\n",
    "    )\n",
    "\n",
    "    # Set x-axis title\n",
    "    fig.update_xaxes(title_text=\"Hour\")\n",
    "\n",
    "    # Set y-axes titles\n",
    "    fig.update_yaxes(title_text=\"<b>Cumulative Conflicting Index</b>\", secondary_y=False)\n",
    "    fig.update_yaxes(title_text=\"<b>{0} Count({1})</b>\".format(objclass.title(), metric), secondary_y=True)\n",
    "\n",
    "    fig.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5873a874390e4534aa6cafd27262f173",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(RadioButtons(description='objclass', options=('car', 'pedestrian'), value='car'), RadioB…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = interact(lineplot_hour_conflicting, metric=widgets.RadioButtons(options=['median', 'mean', \"max\"]),\n",
    "             objclass=widgets.RadioButtons(options=['car', 'pedestrian']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By comparing the line plots of cumulative conflicting index and count of pedestrians or cars, we can notice that there is no strong correlation between the two numbers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Show plot with the highest density, indicating where is the largest conflicting point\n",
    "def heatmap_hour_conflicting(hour):\n",
    "    \n",
    "    image = mpimg.imread('underraincoat_sandbox.png')\n",
    "    fig, ax = plt.subplots(figsize=(14,10))\n",
    "    ax.imshow(image, aspect='auto')\n",
    "    data = high_traffic_day_hourly_heatmap[high_traffic_day_hourly_heatmap['hour'] == hour]\n",
    "    scatter = culmulative_heat_map_data(data['conflictIndexMatrix'].tolist())\n",
    "    x = [i[0] for i in scatter]\n",
    "    y =  [i[1] for i in scatter]\n",
    "    density = [i[2] for i in scatter]\n",
    "    ax.scatter(x,  y, c= density, cmap = plt.cm.YlGnBu_r)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(\"The Conflicting Heatmap between Pedestrian and Car at {0}\".format(hour), fontsize = 20, y = 1.05)\n",
    "    fig.colorbar(plt.cm.ScalarMappable(norm=mcolors.Normalize(), cmap=plt.cm.YlGnBu_r))\n",
    "    ax.text(750, 300, s =\"Color Bar of Conflicting Index (Scaled)\", fontsize = 14,rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e824c798439425f98a66094787be4ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=7, description='Time (hour):', max=22, min=7), Output()), _dom_classes=(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = interact(heatmap_hour_conflicting,\n",
    "             hour=widgets.IntSlider(min=7, max=22, step=1, value=1, description='Time (hour):'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While cars travel along the road on the right, the conflicts only occur at the upper right corner. To improve safety, we can hang a slow down road sign there to alert drivers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Maintenance Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need hourly data so writing the query again; can combine with the previous one later\n",
    "def get_dwell_by_hour(func, ID):\n",
    "    '''\n",
    "    func is either feedDwellTimeDistribution or zoneDwellTimeDistribution\n",
    "    '''\n",
    "    if func == 'feedDwellTimeDistribution':\n",
    "        arg = 'serialnos: \"{0}\"'.format(ID)\n",
    "    else:\n",
    "        arg = 'zoneIds: {0}'.format(ID)\n",
    "        \n",
    "    query = \"\"\"\n",
    "    query {{\n",
    "        {0}(\n",
    "        {1},\n",
    "        startTime: \"2019-02-20T00:00:00\",\n",
    "        endTime: \"2020-01-12T00:00:00\",\n",
    "        timezone: \"America/New_York\",\n",
    "        objClasses: [\"pedestrian\"],\n",
    "        interval: \"1h\"\n",
    "        ){{\n",
    "        edges {{\n",
    "          node {{\n",
    "            time\n",
    "            objClass\n",
    "            pct100\n",
    "            pct75\n",
    "            pct50\n",
    "            pct25\n",
    "            mean\n",
    "            count\n",
    "          }}\n",
    "        }}\n",
    "      }}\n",
    "    }}\n",
    "    \"\"\".format(func, arg)\n",
    "\n",
    "    dwell = requests.post(url, json={'query': query}, \n",
    "                           headers = {'Authorization':token})\n",
    "    \n",
    "    df = pd.DataFrame([x['node'] for x in dwell.json()['data'][func]['edges']])\n",
    "    if func == 'feedDwellTimeDistribution':\n",
    "        df['device'] = ID\n",
    "    else:\n",
    "        df['zone'] = ID\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_dwell_df = pd.concat([get_dwell_by_hour('feedDwellTimeDistribution', device_ids[i]) \n",
    "                           for i in range(3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace NaN with 0\n",
    "feed_dwell_df = feed_dwell_df.fillna(0)\n",
    "\n",
    "# convert time to timestamp object\n",
    "feed_dwell_df['time'] = feed_dwell_df['time'].str[:-6].apply(lambda x : pd.Timestamp(x))\n",
    "\n",
    "# add name column in addition to ID\n",
    "feed_dwell_df['device_name'] = [device_dict[d] for d in feed_dwell_df.device]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "from pandas.api.types import CategoricalDtype\n",
    "days = [(dt.datetime(2019, 3, 4) + dt.timedelta(days=x)).strftime('%a') for x in range(0, 7)]\n",
    "day_type = CategoricalDtype(categories=days, ordered=True)\n",
    "\n",
    "feed_dwell_df['day of week'] = feed_dwell_df['time'].apply(lambda x: x.strftime('%a')).astype(day_type)\n",
    "feed_dwell_df['date'] = feed_dwell_df['time'].apply(lambda x: x.strftime('%Y-%m-%d'))\n",
    "feed_dwell_df['hour'] = feed_dwell_df['time'].apply(lambda x: x.strftime('%H'))\n",
    "feed_dwell_df['hour'] = pd.to_numeric(feed_dwell_df['hour'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_count = feed_dwell_df.groupby(['date', 'device_name'])['count'].max()\n",
    "daily_count = pd.DataFrame(daily_count).reset_index()\n",
    "daily_count['date'] = pd.to_datetime(daily_count['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maintenance_df(df, device, threshold, service):\n",
    "    dev_df = df[df['device_name'] == device]\n",
    "    \n",
    "    need_extra = []\n",
    "    need_regular = []\n",
    "    unmaintained = []\n",
    "    visualize = []\n",
    "    cumulative = 0\n",
    "\n",
    "    for index, row in dev_df.iterrows():\n",
    "        if row['count'] >= threshold:\n",
    "            need_extra.append(1)\n",
    "            need_regular.append(0)\n",
    "            if service == 'both' or service == 'extra':\n",
    "                visualize.append(row['count'])\n",
    "            else:\n",
    "                visualize.append(0)\n",
    "            cumulative = 0\n",
    "\n",
    "        else:\n",
    "            need_extra.append(0)\n",
    "            cumulative += row['count']\n",
    "            if cumulative >= threshold:\n",
    "                need_regular.append(1)\n",
    "                if service == 'both' or service == 'regular':\n",
    "                    visualize.append(cumulative)\n",
    "                else:\n",
    "                    visualize.append(0)\n",
    "                cumulative = 0\n",
    "            else:\n",
    "                visualize.append(0)\n",
    "                need_regular.append(0)\n",
    "\n",
    "        unmaintained.append(cumulative)\n",
    "\n",
    "    dev_df['need_extra'] = need_extra\n",
    "    dev_df['need_regular'] = need_regular\n",
    "    dev_df['unmaintained'] = unmaintained\n",
    "    dev_df['visualize'] = visualize\n",
    "        \n",
    "    return dev_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Maintenance Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the maximum hourly pedestrian count every day\n",
    "daily_count = feed_dwell_1h_df.groupby(['date', 'device'])['count'].max()\n",
    "daily_count = pd.DataFrame(daily_count).reset_index()\n",
    "daily_count = daily_count.rename(columns={'count': 'pedestrian count'})\n",
    "daily_count['date'] = pd.to_datetime(daily_count['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the total duration every day\n",
    "daily_duration = feed_dwell_1d_df.groupby(['date','device'])['total_dwell'].mean()\n",
    "daily_duration = pd.DataFrame(daily_duration).reset_index()\n",
    "# convert from second to hour\n",
    "daily_duration['dwell hour'] = daily_duration['total_dwell'] / 60\n",
    "daily_duration = daily_duration.drop(columns=['total_dwell'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Maintenance schedule by pedestrian count or dwell time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maintenance_df(df, device, threshold, service, metric):\n",
    "    \"\"\"\n",
    "    This function returns a dataframe of days when extra or \n",
    "    regular maintenance is needed. Extra maintenance is scheduled\n",
    "    on days with daily pedestrian count over threshold; regular \n",
    "    maintenance is scheduled when cumulative unmaintained visitors\n",
    "    over several days is over threshold. Service is for displaying\n",
    "    both/extra/regular type of maintenance. Metric is by pedestrian\n",
    "    count or dwell hours.\n",
    "    \"\"\"\n",
    "    dev_df = df[df['device'] == device]\n",
    "    \n",
    "    need_extra = []\n",
    "    need_regular = []\n",
    "    unmaintained = []\n",
    "    visualize = []\n",
    "    cumulative = 0\n",
    "\n",
    "    for index, row in dev_df.iterrows():\n",
    "        if row[metric] >= threshold:\n",
    "            need_extra.append(1)\n",
    "            need_regular.append(0)    \n",
    "            if service == 'both' or service == 'extra':\n",
    "                # display extra maintenance\n",
    "                visualize.append(row[metric])\n",
    "            else: # don't display extra maintenance\n",
    "                visualize.append(0)\n",
    "            # reset unmaintained number\n",
    "            cumulative = 0\n",
    "\n",
    "        else: # check if regular maintenance is needed\n",
    "            need_extra.append(0)\n",
    "            # update unmaintained number of visitors\n",
    "            cumulative += row[metric]\n",
    "            if cumulative >= threshold: # need regular maintanence\n",
    "                need_regular.append(1)\n",
    "                if service == 'both' or service == 'regular':\n",
    "                    visualize.append(cumulative)\n",
    "                else: # don't display regular maintenance\n",
    "                    visualize.append(0)\n",
    "                # reset maintenance\n",
    "                cumulative = 0\n",
    "            else: # don't need regular maintenance\n",
    "                visualize.append(0)\n",
    "                need_regular.append(0)\n",
    "\n",
    "        unmaintained.append(cumulative)\n",
    "\n",
    "    # create columns in dataframe\n",
    "    dev_df['need_extra'] = need_extra\n",
    "    dev_df['need_regular'] = need_regular\n",
    "    dev_df['unmaintained'] = unmaintained\n",
    "    dev_df['visualize'] = visualize\n",
    "        \n",
    "    return dev_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_maintenance(start_date, end_date, threshold, service, metric): \n",
    "    \"\"\"\n",
    "    This function plots a calendar heatmap of the maintenance schedule \n",
    "    for three devices between start_date and end_date. \n",
    "    Threshold is the number of visitors for one required maintenance.\n",
    "    \"\"\"\n",
    "    # select date range and metric\n",
    "    if metric == 'pedestrian count':\n",
    "        plot_df = daily_count.loc[(daily_count.date >= pd.Timestamp(start_date)) & \n",
    "                     (daily_count.date <= pd.Timestamp(end_date))].copy()\n",
    "    else:\n",
    "        plot_df = daily_duration.loc[(daily_count.date >= pd.Timestamp(start_date)) & \n",
    "                     (daily_count.date <= pd.Timestamp(end_date))].copy()\n",
    "    \n",
    "    # create maintenance dataframe for three devices\n",
    "    dev1 = maintenance_df(plot_df, 'Streetscape', threshold, service, metric)\n",
    "    dev2 = maintenance_df(plot_df, 'Under Raincoat', threshold, service, metric)\n",
    "    dev3 = maintenance_df(plot_df, 'Outside', threshold, service, metric)\n",
    "    \n",
    "    dev_y = ['Streetscape', 'Under Raincoat', 'Outside']\n",
    "    # reverse order of list for consistency in plotting\n",
    "    dev_y = dev_y[::-1]\n",
    "    # create list of series for plotting heatmap\n",
    "    dev_z = [dev1['visualize'], dev2['visualize'], dev3['visualize']]\n",
    "    dev_z = dev_z[::-1]\n",
    "\n",
    "    fig = go.Figure(data=go.Heatmap(\n",
    "            z=dev_z,\n",
    "            x=dev3['date'],\n",
    "            y=dev_y,\n",
    "            colorscale='Hot_r'))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title='Maintenance schedule by {}'.format(metric),\n",
    "        xaxis_nticks=36)\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f36836c2f384ee5b904064cb81f206d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(DatePicker(value=Timestamp('2019-02-20 00:00:00'), description='start_date'), DatePicker…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = interact(plot_maintenance, \n",
    "             service=widgets.Dropdown(options=['both', 'extra', 'regular'], value='both', disabled=False),\n",
    "             start_date=widgets.DatePicker(value=pd.to_datetime('2019-02-20')),\n",
    "             end_date=widgets.DatePicker(value=pd.to_datetime('2020-01-12')),\n",
    "             threshold=widgets.IntSlider(value=500, min=300, max=1000, step=100, readout_format='d'),\n",
    "             metric=widgets.Dropdown(options=['pedestrian count', 'dwell hour'], \n",
    "                                      value='pedestrian count', disabled=False),\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are required to plan a maintenance schedule by people (every 500 visitors) or time (every 500 hours), and you can see either plan by selecting `pedestrian count` or `dwell time` from the dropdown list `metric` on the interactive plot. You can customize time period of maintenance to be displayed. You can also change the value of `threshold`, to see how the schedule would change for a value other than 500.\n",
    "\n",
    "The maintenance schedule is planned as such: First we would check if it is a busy day with pedestrian count or dwell time more than 500. If so, an extra maintenance would be schedule on that day; otherwise, this number is added to the number of unmaintained visitors or hours. When the unmaintained number exceeds 500, a regular maintenance would be scheduled. Every time a maintenace is scheduled, the unmaintained number clears to zero. On the interactive plot, you can view both types of maintenance, or select only `extra` or `regular`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that Streetscape needs the most frequent maintenance, while Under Raincoat needs the least. If we are planning an event, we should plan for an extra maintenance at Streetscape, but for Under Raincoat and Outside, regular maintenance would be enough unless we expect the event to be very popular.\n",
    "\n",
    "We also notice that busy months during the year (April - November) needs more maintenance than Winter months (December - March), so we could plan different schedules for the two periods. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maintenance Time During the Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reformat day of week\n",
    "feed_dwell_1h_df = feed_dwell_1h_df.replace({'dayofweek':{0:'Mon', 1:'Tue', 2:'Wed', 3:'Thu', 4:'Fri',\n",
    "                                                         5:'Sat', 6:'Sun'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hour_heatmap(selected, start_date, end_date, service, threshold, metric):\n",
    "    \"\"\"\n",
    "    This function plots a calendar heatmap by hour and day of week, where one grid represents\n",
    "    pedestrian count/dwell time during that hour, based on the metric selected. \n",
    "    The user can specify a threshold, choose selected area, and service of extra or regular. \n",
    "    \"\"\"\n",
    "    df = feed_dwell_1h_df.rename(columns={'count': 'pedestrian count'})\n",
    "    df['dwell hour'] = df['total_dwell'] / 60\n",
    "    \n",
    "    # select time range\n",
    "    plot_df = df.loc[(pd.to_datetime(df.date) >= pd.Timestamp(start_date)) & \n",
    "                     (pd.to_datetime(df.date) <= pd.Timestamp(end_date))].copy()\n",
    "    \n",
    "    # select device\n",
    "    if selected != 'all':\n",
    "        plot_df = plot_df[plot_df['device'] == selected]\n",
    "    \n",
    "    # exclude number from busy hours to display regular pedestrian count/dwell time\n",
    "    if service == 'regular':\n",
    "        plot_df = plot_df[plot_df[metric] < threshold]\n",
    "    \n",
    "    # select metric\n",
    "    if metric == 'pedestrian count':\n",
    "        hourly_count = plot_df.groupby(['dayofweek', 'hour'])['pedestrian count'].mean()\n",
    "    else:\n",
    "        hourly_count = plot_df.groupby(['dayofweek', 'hour'])['dwell hour'].mean()\n",
    "           \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    hourly_count = pd.DataFrame(hourly_count).reset_index()\n",
    "        \n",
    "    days = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "    # reverse list order for display\n",
    "    days = days[::-1]\n",
    "    count = []\n",
    "    count = count[::-1]\n",
    "    # create list for display\n",
    "    \n",
    "    for day in days:\n",
    "        count.append(hourly_count[hourly_count['dayofweek'] == day][metric].tolist())\n",
    "\n",
    "    fig = go.Figure(data=go.Heatmap(\n",
    "                   z=count,\n",
    "                   y=days,\n",
    "                   x=[0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
    "       17, 18, 19, 20, 21, 22, 23],\n",
    "                   colorscale='YlOrRd',\n",
    "                   hoverongaps = False))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"Calendar heatmap of {} by hour and day of week\".format(metric),\n",
    "        xaxis = dict(\n",
    "        tickmode = 'linear',\n",
    "        dtick = 1,\n",
    "        title = 'hour in the day')\n",
    "    )\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b55d6031592436cbfbc8c5fffd8ef77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='selected', index=1, options=('all', 'Streetscape', 'Under Raincoat…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = interact(plot_hour_heatmap, \n",
    "             selected=widgets.Dropdown(options=['all', 'Streetscape', 'Under Raincoat', 'Outside'], \n",
    "                                       value='Streetscape', disabled=False),\n",
    "             start_date=widgets.DatePicker(value=pd.to_datetime('2019-02-20')),\n",
    "             end_date=widgets.DatePicker(value=pd.to_datetime('2020-01-12')),\n",
    "             service=widgets.Dropdown(options=['extra', 'regular'], value='regular', disabled=False),\n",
    "             threshold=widgets.IntSlider(value=500, min=300, max=1000, step=100, readout_format='d'),\n",
    "             metric=widgets.Dropdown(options=['pedestrian count', 'dwell hour'], \n",
    "                                      value='pedestrian count', disabled=False)\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally, we want to plan for a regular maintenance time during the day, so we visualize the hourly count by hour and by day of the week using a calendar heatmap. You can select an area from `selected`, and customize the time range. You can select a `threshold` for busy hours (the default is set as 500). You can also select the type of service to play, if you choose `regular`, data of busy hours with a number of `threshold` would be excluded.\n",
    "\n",
    "There are more activities during 8:00-20:00, and we would recommend scheduling the maintenance time during 7:00-8:00 or 19:00-20:00. These are time slots with less people, but not too early or too late for maintenance staff to come to work.\n",
    "\n",
    "For Streetscape, we also notice that there are more people on Sunday afternoons, probably because of the visitors attending open hours. For `regular` service at Streetscape, there are much fewer people on Saturdays than other days; but for `extra` service, the difference is less significant. This indicates that Saturdays have fewer people on usual days, but some popular events were scheduled on Saturdays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Privacy Philosophy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection\n",
    "\n",
    "The data collected and stored by Numina are object data extracted from detection images collected by sensors. The images are not stored or sent to any other server, and they are deleted from the sensor immediately after it has been processed.\n",
    "\n",
    "For testing purposes, Numina has to collect images once per hour, at low resolutions, random times, and at minimal quantities.\n",
    "\n",
    "It is concerned by many people that the data are tracked without consent. However, the potential risk is very low as Numina de-identifies individuals at source at the time of collection. Because of the deidentification, the data collection does not violate [Canadian privacy law](https://laws-lois.justice.gc.ca/eng/acts/P-8.6/page-1.html#h-416888), which states that companies must gain consent before collecting personal information that relates to an identifiable individual. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "\n",
    "The data used for generating all contents on this website are de-identified data in JSON text format. The data are aggregation of individual dwell time and movement path during a given time. We are not given the data of individual paths or track ids, nor do we try to identify any individual tracks. Instead, we perform analysis on the population data to explore general trends or patterns for dwell time and heatmap. Therefore, our data process methods respect individual privacy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Improvements\n",
    "\n",
    "Our goal for data privacy is to balance individual privacy and benefits for society. To address the difficulty of obtaining consent for data collection in public spaces, we can inform visitors about the data collection method via different ways of communication:\n",
    "- We can hang posters and infographics about data collection and data privacy of the Numina sensors in the area being captured.\n",
    "- We can provide QR code at the entrance/exit for visitors who are interested to know more.\n",
    "\n",
    "We also notice many limitations during our work of creating the webpage. For example, without data of real pedestrian behaviours or event records, we need to make many assumptions for the possible explanations of our findings, which may be inaccurate. Therefore, we could improve our analysis by integrating qualitative data collected during surveys or Q&A sessions. It is also much easire to ask for consent for these methods of data collection. The qualitative data would help us understand the behaviours behind our data, and to make better design choices."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
